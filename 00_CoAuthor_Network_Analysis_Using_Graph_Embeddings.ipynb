{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "CoAuthor Network Analysis Using Graph Embeddings ",
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'arxiv:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F612177%2F4823527%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240229%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240229T190420Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4cccfdbb054aca815504912a917bfa1e9d2b656dba855fa88a62679feb87d2b4bdfdc5dd4f47b46f8c433b10b96433b22484bbcfa431998c0e3fc85e6d9cb26474a62d8a9c48cd9d1b9ecde8cdb0ec50ce913e7a1cb0109e353b19f277af9da0434894790b98e1b4cfa20aca7f7c004e9e594cba8e641bd4f365efe1760488fc0a46e3c960bd4cac0d09aa3b4b1fbbf44971ad10247f932fbce767f1b53cacd97e35a04bfc60c8e3a3cc05eb57dadf42129f972434e6e09ee2b4f2e88cb587eb67d8041be8fb22d353437529f3d7ba4336e918b8bc6fe5a168776d0094d85e5d800382f9a67accaac90137e37756292fef55daebcb07679ae3baf9746ed4767c'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "WPbTf6zoQNlg"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T17:16:41.900509Z",
          "iopub.execute_input": "2021-06-10T17:16:41.901023Z",
          "iopub.status.idle": "2021-06-10T17:16:41.942584Z",
          "shell.execute_reply.started": "2021-06-10T17:16:41.900993Z",
          "shell.execute_reply": "2021-06-10T17:16:41.941971Z"
        },
        "trusted": true,
        "id": "FzBq_qraQNlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In this we will look at Arxiv papers published in ML and AI since the year 2015- with focus of Co-Author Network.We will use Deep Walk (which is a concept based of Word Embeddings) to cluster author networks.\n",
        "This kind of embedding a Graph, can help in applications like clustering, Link PRediction etc.\n",
        "\n",
        "For Visualising the Graph we will use pyvis"
      ],
      "metadata": {
        "id": "uVKNV-YvQNlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyvis"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:30:58.925963Z",
          "iopub.execute_input": "2023-01-13T10:30:58.926754Z",
          "iopub.status.idle": "2023-01-13T10:31:12.769723Z",
          "shell.execute_reply.started": "2023-01-13T10:30:58.926646Z",
          "shell.execute_reply": "2023-01-13T10:31:12.768397Z"
        },
        "trusted": true,
        "id": "JyUIlWZkQNlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Libraries"
      ],
      "metadata": {
        "id": "Z6uvRykoQNlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import ast\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "#import nltk\n",
        "#from nltk.corpus import stopwords\n",
        "#import spacy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "import networkx as nx\n",
        "from networkx.algorithms.components.connected import connected_components\n",
        "\n",
        "import json\n",
        "import dask.bag as db\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import json\n",
        "\n",
        "\n",
        "from itertools import combinations\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "import random\n",
        "\n",
        "from tqdm.notebook import tqdm, trange\n",
        "import time    # to be used in loop iterations\n",
        "\n",
        "import multiprocessing\n",
        "import smart_open\n",
        "\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "from pyvis.network import Network\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:34:24.588114Z",
          "iopub.execute_input": "2023-01-13T10:34:24.588537Z",
          "iopub.status.idle": "2023-01-13T10:34:28.27617Z",
          "shell.execute_reply.started": "2023-01-13T10:34:24.588498Z",
          "shell.execute_reply": "2023-01-13T10:34:28.275Z"
        },
        "trusted": true,
        "id": "4qaYW0uxQNlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract the Data from Kaggle"
      ],
      "metadata": {
        "id": "FeR6ML2KQNlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract Only the AI , ML PAPERS\n",
        "def extractArxivData(categories=['stat.ML','cs.AI'],year=None,raw_data_path=\"../data/raw/\",save_extracted_filename=\"../data/processed/AI_ML.json\"):\n",
        "    \"\"\" This function extracts data for the given set of categories and save the data into the save_extracted_filename path \"\"\"\n",
        "    records=db.read_text(raw_data_path+\"/*.json\").map(lambda x:json.loads(x))\n",
        "    docs = (records.filter(lambda x:any(ele in x['categories'] for ele in categories)==True))\n",
        "    extract_latest_version=lambda x:x['versions'][-1][\"created\"]\n",
        "    if year!=None:\n",
        "        docs=docs.filter(lambda x:int(extract_latest_version(x).split(\" \")[3])>=year)\n",
        "\n",
        "    get_metadata = lambda x: {'id': x['id'],\n",
        "                  'title': x['title'],\n",
        "                  'category':x['categories'],\n",
        "                  'abstract':x['abstract'],\n",
        "                 'version':x['versions'][-1]['created'],\n",
        "                         'doi':x[\"doi\"],\n",
        "                         'authors_parsed':x['authors_parsed']}\n",
        "\n",
        "    data=docs.map(get_metadata).to_dataframe().compute()\n",
        "\n",
        "    ## Creating authors fields by joining first and last nmes in authors_parsed columns.\n",
        "    data['authors']=data['authors_parsed'].apply(lambda authors:[(\" \".join(author)).strip() for author in authors])\n",
        "\n",
        "    print(\"Number of Records Extracted for Given Set of Categories \",data.shape[0])\n",
        "    Path(os.path.dirname(save_extracted_filename)).mkdir(parents=True, exist_ok=True)\n",
        "    data.to_json(save_extracted_filename,orient=\"records\")\n",
        "    return data\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:34:28.27815Z",
          "iopub.execute_input": "2023-01-13T10:34:28.278616Z",
          "iopub.status.idle": "2023-01-13T10:34:28.29073Z",
          "shell.execute_reply.started": "2023-01-13T10:34:28.278564Z",
          "shell.execute_reply": "2023-01-13T10:34:28.289318Z"
        },
        "trusted": true,
        "id": "2oDMXWpMQNlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RAW_DATA_PATH=\"../input/arxiv/\"\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:34:29.347651Z",
          "iopub.execute_input": "2023-01-13T10:34:29.348424Z",
          "iopub.status.idle": "2023-01-13T10:34:29.353458Z",
          "shell.execute_reply.started": "2023-01-13T10:34:29.34837Z",
          "shell.execute_reply": "2023-01-13T10:34:29.352577Z"
        },
        "trusted": true,
        "id": "q384nO3rQNll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Collect data for Papers published in ['stat.ML','cs.AI'] since year 2015.\n",
        "data=extractArxivData(categories=['stat.ML','cs.AI'],year=2015,raw_data_path=RAW_DATA_PATH,save_extracted_filename=\"AI_ML_since2015.json\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:34:31.023004Z",
          "iopub.execute_input": "2023-01-13T10:34:31.023636Z",
          "iopub.status.idle": "2023-01-13T10:36:02.374256Z",
          "shell.execute_reply.started": "2023-01-13T10:34:31.023573Z",
          "shell.execute_reply": "2023-01-13T10:36:02.372478Z"
        },
        "trusted": true,
        "id": "DzIHADdeQNll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Co-Author Network\n",
        "\n",
        "For the set of papers extracted, for every pair of authors an edge is to be created. The Edge weight will be the number of papers the two authors have collabrated on."
      ],
      "metadata": {
        "id": "sr064dQyQNll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Data\n"
      ],
      "metadata": {
        "id": "RgjYWjCTQNll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['author_pairs']=data['authors'].apply(lambda x:list(combinations(x, 2)))\n",
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:36:02.376514Z",
          "iopub.execute_input": "2023-01-13T10:36:02.376996Z",
          "iopub.status.idle": "2023-01-13T10:36:02.682591Z",
          "shell.execute_reply.started": "2023-01-13T10:36:02.376956Z",
          "shell.execute_reply": "2023-01-13T10:36:02.681345Z"
        },
        "trusted": true,
        "id": "gGRCCBbfQNll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For our Analysis, we will consider authors who have published papers after 2015 and published more than 2 papers.\n"
      ],
      "metadata": {
        "id": "ygf7AsySQNll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flattenList(nested_list):\n",
        "    flat_list = [item for sublist in nested_list for item in sublist]\n",
        "    return flat_list\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:37:06.570955Z",
          "iopub.execute_input": "2023-01-13T10:37:06.571829Z",
          "iopub.status.idle": "2023-01-13T10:37:06.578621Z",
          "shell.execute_reply.started": "2023-01-13T10:37:06.571755Z",
          "shell.execute_reply": "2023-01-13T10:37:06.57746Z"
        },
        "trusted": true,
        "id": "C-OxQC99QNlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ai_authors=pd.DataFrame(flattenList(data['authors'].tolist())).rename(columns={0:'authors'})\n",
        "papers_by_authors=ai_authors.groupby(['authors']).size().reset_index().rename(columns={0:'Number of Papers Published'}).sort_values(\"Number of Papers Published\",ascending=False)\n",
        "papers_by_authors.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:37:06.766292Z",
          "iopub.execute_input": "2023-01-13T10:37:06.767015Z",
          "iopub.status.idle": "2023-01-13T10:37:07.388213Z",
          "shell.execute_reply.started": "2023-01-13T10:37:06.766971Z",
          "shell.execute_reply": "2023-01-13T10:37:07.386812Z"
        },
        "trusted": true,
        "id": "zaFmJZdwQNlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "papers_by_authors['Number of Papers Published'].describe()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:37:08.710577Z",
          "iopub.execute_input": "2023-01-13T10:37:08.711319Z",
          "iopub.status.idle": "2023-01-13T10:37:08.734879Z",
          "shell.execute_reply.started": "2023-01-13T10:37:08.711264Z",
          "shell.execute_reply": "2023-01-13T10:37:08.73342Z"
        },
        "trusted": true,
        "id": "6xy9kIPzQNlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Keeping Authors who have published more than 2 Papers\n",
        "nodes_to_keep=papers_by_authors.loc[papers_by_authors['Number of Papers Published']>2,'authors'].tolist()\n",
        "len(nodes_to_keep)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:37:09.008143Z",
          "iopub.execute_input": "2023-01-13T10:37:09.008599Z",
          "iopub.status.idle": "2023-01-13T10:37:09.022496Z",
          "shell.execute_reply.started": "2023-01-13T10:37:09.008551Z",
          "shell.execute_reply": "2023-01-13T10:37:09.021029Z"
        },
        "trusted": true,
        "id": "6ADPDVSbQNlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating the Edges of the Co-Author Network"
      ],
      "metadata": {
        "id": "ut7d34yTQNlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "authors_pairs=data['author_pairs'].tolist()\n",
        "authors_edge_list=[item for sublist in authors_pairs for item in sublist]\n",
        "authors_weighted_edge_list=list(Counter(authors_edge_list).items())\n",
        "authors_weighted_edge_list=[(row[0][0],row[0][1],row[1]) for idx,row in enumerate(authors_weighted_edge_list)]\n",
        "authors_weighted_edge_list[0:10]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:37:12.691064Z",
          "iopub.execute_input": "2023-01-13T10:37:12.691494Z",
          "iopub.status.idle": "2023-01-13T10:37:13.868294Z",
          "shell.execute_reply.started": "2023-01-13T10:37:12.691452Z",
          "shell.execute_reply": "2023-01-13T10:37:13.866903Z"
        },
        "trusted": true,
        "id": "_wh66BeeQNlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Graph on the Complete Data"
      ],
      "metadata": {
        "id": "Aj_vFRMDQNlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G1=nx.Graph()\n",
        "G1.add_weighted_edges_from(authors_weighted_edge_list)\n",
        "print(len(G1.nodes()))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:37:16.9869Z",
          "iopub.execute_input": "2023-01-13T10:37:16.98755Z",
          "iopub.status.idle": "2023-01-13T10:37:19.843453Z",
          "shell.execute_reply.started": "2023-01-13T10:37:16.987485Z",
          "shell.execute_reply": "2023-01-13T10:37:19.842133Z"
        },
        "trusted": true,
        "id": "br-GmzAcQNlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtering the Graph, to keep nodes (authors) who have atleast published 3 papers. We will also remove any isolated nodes in the generated network"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T17:22:51.692696Z",
          "iopub.execute_input": "2021-06-10T17:22:51.693185Z",
          "iopub.status.idle": "2021-06-10T17:22:51.744902Z",
          "shell.execute_reply.started": "2021-06-10T17:22:51.693141Z",
          "shell.execute_reply": "2021-06-10T17:22:51.744116Z"
        },
        "id": "TJ6yvw0yQNlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## From the complete Graph, create a subgraph, with only the nodes to keep\n",
        "sub_g=nx.subgraph(G1,nodes_to_keep)\n",
        "G=nx.Graph(sub_g)\n",
        "print(len(G.nodes()))\n",
        "isolated_node=nx.isolates(G)\n",
        "len(list(isolated_node))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:37:22.043603Z",
          "iopub.execute_input": "2023-01-13T10:37:22.044004Z",
          "iopub.status.idle": "2023-01-13T10:37:25.886603Z",
          "shell.execute_reply.started": "2023-01-13T10:37:22.043952Z",
          "shell.execute_reply": "2023-01-13T10:37:25.885527Z"
        },
        "trusted": true,
        "id": "Cs1ED0J-QNlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.remove_nodes_from(list(nx.isolates(G)))\n",
        "len(G.nodes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:37:25.88825Z",
          "iopub.execute_input": "2023-01-13T10:37:25.888579Z",
          "iopub.status.idle": "2023-01-13T10:37:25.9306Z",
          "shell.execute_reply.started": "2023-01-13T10:37:25.888546Z",
          "shell.execute_reply": "2023-01-13T10:37:25.929284Z"
        },
        "trusted": true,
        "id": "Y2Omm4EwQNlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del G1, sub_g"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:37:25.932947Z",
          "iopub.execute_input": "2023-01-13T10:37:25.933434Z",
          "iopub.status.idle": "2023-01-13T10:37:26.240662Z",
          "shell.execute_reply.started": "2023-01-13T10:37:25.933373Z",
          "shell.execute_reply": "2023-01-13T10:37:26.239626Z"
        },
        "trusted": true,
        "id": "3_Y6lCqFQNlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of Nodes in Author Graph \",len(G.nodes()))\n",
        "print(\"Number of Edges in AUthor Graph \",len(G.edges()))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:37:26.242213Z",
          "iopub.execute_input": "2023-01-13T10:37:26.242739Z",
          "iopub.status.idle": "2023-01-13T10:37:26.276427Z",
          "shell.execute_reply.started": "2023-01-13T10:37:26.242696Z",
          "shell.execute_reply": "2023-01-13T10:37:26.275415Z"
        },
        "trusted": true,
        "id": "IELN8oePQNlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Deep Walk\n",
        "\n",
        "**Deep walk uses the concept of Random Walks to assign an embedding to each node in the network.**\n",
        "\n",
        "1. In Random Walk, given a node we pick one of its neighbours at random and move to this node and from this node again choose another node among its neighbours at random. This continues for a fixed number of steps.\n",
        "\n",
        "\n",
        "\n",
        "2. Once we have random walks generated for every node in the network, in DeepWalk the next step is to predict probability of visiting node \"v\" on a random walk starting from node \"u\".\n",
        "\n",
        "3. This is very similar to the Skip-Gram model used in Word2Vec Model in NLP, wherein we try to predict the neighbouring words given a particular target word.\n",
        "\n",
        "\n",
        "### Define Function for Random Walk\n"
      ],
      "metadata": {
        "id": "yu7qoBxUQNlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getRandomWalk(graph,node,length_of_random_walk):\n",
        "    \"\"\" This function takes NetworkX Graph and a Node and generate random walk for a given length\n",
        "\n",
        "    Returns the random walk (list of nodes traversed)\n",
        "\n",
        "    Note: The same node may occcur more than once in a Random Walk.\n",
        "    \"\"\"\n",
        "    start_node=node\n",
        "    current_node=start_node\n",
        "    random_walk=[node]\n",
        "    for i in range(0,length_of_random_walk):\n",
        "        ## Choose a random neighbour of the current node\n",
        "\n",
        "        current_node_neighbours=list(graph.neighbors(current_node))\n",
        "        chosen_node=random.choice(current_node_neighbours)\n",
        "        current_node=chosen_node\n",
        "        random_walk.append(current_node)\n",
        "    return random_walk\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:37:53.461601Z",
          "iopub.execute_input": "2023-01-13T10:37:53.462472Z",
          "iopub.status.idle": "2023-01-13T10:37:53.470318Z",
          "shell.execute_reply.started": "2023-01-13T10:37:53.462408Z",
          "shell.execute_reply": "2023-01-13T10:37:53.469111Z"
        },
        "trusted": true,
        "id": "DpvoocGqQNlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### For every Node in the Graph, get randomwalks . For eahc node, let us get random walks say around 10 times each of path length 10\n",
        "num_sampling=10\n",
        "random_walks=[]\n",
        "length_of_random_walk=10\n",
        "for node in tqdm(G.nodes(),desc=\"Iterating Nodes\"):\n",
        "\n",
        "    for i in range(0,num_sampling):\n",
        "        random_walks.append(getRandomWalk(G,node,length_of_random_walk))\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-13T10:37:56.500047Z",
          "iopub.execute_input": "2023-01-13T10:37:56.500821Z",
          "iopub.status.idle": "2023-01-13T10:38:10.766506Z",
          "shell.execute_reply.started": "2023-01-13T10:37:56.500758Z",
          "shell.execute_reply": "2023-01-13T10:38:10.765391Z"
        },
        "trusted": true,
        "id": "qgeoD7_zQNln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data now is similar to list of words in a sentence and we can use gensim to create Node Embedding Model - here each author is a Node and Node is similar to word in a sentence"
      ],
      "metadata": {
        "id": "22wTeXE2QNln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deepwalk_model=Word2Vec(sentences=random_walks,window=5,sg=1,negative=5,\n",
        "                        vector_size=128,epochs=20,compute_loss=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:45:01.971942Z",
          "iopub.execute_input": "2023-01-13T10:45:01.972383Z",
          "iopub.status.idle": "2023-01-13T10:49:55.092327Z",
          "shell.execute_reply.started": "2023-01-13T10:45:01.97234Z",
          "shell.execute_reply": "2023-01-13T10:49:55.091348Z"
        },
        "trusted": true,
        "id": "HWNg86G7QNln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deepwalk_model.save(\"deepwalk_since2015.model\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:51:31.609084Z",
          "iopub.execute_input": "2023-01-13T10:51:31.609546Z",
          "iopub.status.idle": "2023-01-13T10:51:31.69651Z",
          "shell.execute_reply.started": "2023-01-13T10:51:31.609504Z",
          "shell.execute_reply": "2023-01-13T10:51:31.694955Z"
        },
        "trusted": true,
        "id": "ky1MG8ZoQNln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets Look who are similar authors"
      ],
      "metadata": {
        "id": "7_MUjTv3QNln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getSimilarNodes(model,node):\n",
        "    \"\"\"\n",
        "    This function takes deepwalk model and a node\n",
        "\n",
        "    Returns the top 10 nodes (author) similar to the given node\n",
        "    \"\"\"\n",
        "    similarity=model.wv.most_similar(node)\n",
        "    similar_nodes=pd.DataFrame()\n",
        "    similar_nodes['Similar_Node']=[row[0] for i,row in enumerate(similarity)]\n",
        "    similar_nodes['Similarity_Score']=[row[1] for i,row in enumerate(similarity)]\n",
        "    similar_nodes['Source_Node']=node\n",
        "    return similar_nodes\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:51:33.870471Z",
          "iopub.execute_input": "2023-01-13T10:51:33.870859Z",
          "iopub.status.idle": "2023-01-13T10:51:33.881179Z",
          "shell.execute_reply.started": "2023-01-13T10:51:33.870828Z",
          "shell.execute_reply": "2023-01-13T10:51:33.880006Z"
        },
        "trusted": true,
        "id": "LefCmuP_QNln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "getSimilarNodes(deepwalk_model,\"Bengio Yoshua\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-13T10:53:03.737722Z",
          "iopub.execute_input": "2023-01-13T10:53:03.738244Z",
          "iopub.status.idle": "2023-01-13T10:53:03.794885Z",
          "shell.execute_reply.started": "2023-01-13T10:53:03.738188Z",
          "shell.execute_reply": "2023-01-13T10:53:03.793203Z"
        },
        "trusted": true,
        "id": "K5rF-wNcQNln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top 3 similar authors have recently published a paper **Scaling Equilibrium Propagation to Deep ConvNets by Drastically Reducing its Gradient Estimator Bias**. They have published lot of work together in the recent years.\n",
        "\n",
        "Jo Jason since 2019 has published 7 papers with Yoshua\n"
      ],
      "metadata": {
        "id": "sxD4Aq50QNln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let us look at the CoAuthorship Network of the top popular Authors\n",
        "\n"
      ],
      "metadata": {
        "id": "WXUbnUvSQNln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ai_authors=pd.DataFrame(flattenList(data['authors'].tolist())).rename(columns={0:'authors'})\n",
        "papers_by_authors=ai_authors.groupby(['authors']).size().reset_index().rename(columns={0:'Number of Papers Published'}).sort_values(\"Number of Papers Published\",ascending=False)\n",
        "papers_by_authors"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T16:15:47.986496Z",
          "iopub.execute_input": "2021-06-10T16:15:47.98702Z",
          "iopub.status.idle": "2021-06-10T16:15:48.316839Z",
          "shell.execute_reply.started": "2021-06-10T16:15:47.986987Z",
          "shell.execute_reply": "2021-06-10T16:15:48.315949Z"
        },
        "trusted": true,
        "id": "SzIsOaEeQNln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets get the graph of these top  Authors with their first step neighbours.We consider the authors ranked 4th to 10th to help visualise the clusters better"
      ],
      "metadata": {
        "id": "jK22_cXOQNlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getCoAuthorshipNetwork(graph,initial_nodes):\n",
        "    \"\"\"\n",
        "    This function takes a Graph and list of initial nodes\n",
        "\n",
        "    Returns the set of immediate neighbours of these nodes\n",
        "\n",
        "    \"\"\"\n",
        "    total_neighbours=0\n",
        "    nodes_set=[initial_nodes]\n",
        "    for node in initial_nodes:\n",
        "        #print(node)\n",
        "        neighbours=list(graph.neighbors(node))\n",
        "        total_neighbours=total_neighbours+len(neighbours)\n",
        "\n",
        "        nodes_set.append(neighbours)\n",
        "    print(total_neighbours)\n",
        "    nodes_set=flattenList(nodes_set)\n",
        "    return list(set(nodes_set))\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T16:16:36.983889Z",
          "iopub.execute_input": "2021-06-10T16:16:36.98426Z",
          "iopub.status.idle": "2021-06-10T16:16:37.02823Z",
          "shell.execute_reply.started": "2021-06-10T16:16:36.98422Z",
          "shell.execute_reply": "2021-06-10T16:16:37.027591Z"
        },
        "trusted": true,
        "id": "dLBN1lCwQNlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "coauthor_nodes=getCoAuthorshipNetwork(G,papers_by_authors['authors'].tolist()[4:10])\n",
        "print(\"Number of CoAuthor Nodes \",len(coauthor_nodes))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T17:24:09.002806Z",
          "iopub.execute_input": "2021-06-10T17:24:09.003098Z",
          "iopub.status.idle": "2021-06-10T17:24:09.053981Z",
          "shell.execute_reply.started": "2021-06-10T17:24:09.003073Z",
          "shell.execute_reply": "2021-06-10T17:24:09.053291Z"
        },
        "trusted": true,
        "id": "UUFKPDNGQNlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate a Co-Author Graph from the complete Graph"
      ],
      "metadata": {
        "id": "Df-uLz12QNlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coauthor_subgraph=nx.subgraph(G,coauthor_nodes)\n",
        "print(\"number of edges in the CoAuthor Subgraph \",len(coauthor_subgraph.edges()))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T16:16:41.858262Z",
          "iopub.execute_input": "2021-06-10T16:16:41.858684Z",
          "iopub.status.idle": "2021-06-10T16:16:41.923992Z",
          "shell.execute_reply.started": "2021-06-10T16:16:41.858657Z",
          "shell.execute_reply": "2021-06-10T16:16:41.923393Z"
        },
        "trusted": true,
        "id": "eIU4ur1vQNlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nx.write_gexf(coauthor_subgraph, \"CoAuthor_Subgraph_Author4to10.gexf\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T16:16:56.221796Z",
          "iopub.execute_input": "2021-06-10T16:16:56.222197Z",
          "iopub.status.idle": "2021-06-10T16:16:56.44852Z",
          "shell.execute_reply.started": "2021-06-10T16:16:56.222171Z",
          "shell.execute_reply": "2021-06-10T16:16:56.447884Z"
        },
        "trusted": true,
        "id": "Wp6rpL75QNlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#coauthor_subgraph=nx.read_gexf(\"CoAuthor_Subgraph_Top50Author.gexf\")\n",
        "print(\"number of edges in the CoAuthor Subgraph \",len(coauthor_subgraph.edges()))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T17:24:39.007546Z",
          "iopub.execute_input": "2021-06-10T17:24:39.008143Z",
          "iopub.status.idle": "2021-06-10T17:24:39.09423Z",
          "shell.execute_reply.started": "2021-06-10T17:24:39.008109Z",
          "shell.execute_reply": "2021-06-10T17:24:39.093316Z"
        },
        "trusted": true,
        "id": "JhpDboG0QNlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualise the generated network"
      ],
      "metadata": {
        "id": "ejiKalAmQNlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pyvis_nt=Network(notebook=True,height='800px', width='100%',heading='')\n",
        "\n",
        "print(\"Creating PyVis from NetworkX\")\n",
        "pyvis_nt.from_nx(coauthor_subgraph)\n",
        "\n",
        "print(\"Saving PyVis Graph\")\n",
        "pyvis_nt.show(\"Author4to10_CoAuthorGraph.html\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T16:17:06.01488Z",
          "iopub.execute_input": "2021-06-10T16:17:06.015327Z",
          "iopub.status.idle": "2021-06-10T16:17:08.020912Z",
          "shell.execute_reply.started": "2021-06-10T16:17:06.015282Z",
          "shell.execute_reply": "2021-06-10T16:17:08.02002Z"
        },
        "trusted": true,
        "id": "_XHQDQ0WQNlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see some clusters already. Lets see if embeddings is able to seperate these clusters\n",
        "### Cluster the Nodes - based on Embeddings\n",
        "\n",
        "Idea is to see if similar nodes belong to the same cluster."
      ],
      "metadata": {
        "id": "ADgdV8-sQNlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getCosineDistanceMatrix(vectors):\n",
        "    '''\n",
        "    This function takes list of vectors or numpy array\n",
        "\n",
        "    Returns the pairwise cosine similarity matrix\n",
        "    '''\n",
        "    if type(vectors)==list:\n",
        "        X=np.asarray(vectors)\n",
        "    elif type(vectors)==np.ndarray:\n",
        "        X=vectors\n",
        "    else:\n",
        "        print(\"Error in Data Type . Need to Pass list or numpy array as input argument\")\n",
        "        return []\n",
        "    cosine_dist=cosine_distances(X)\n",
        "    return cosine_dist\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T17:25:02.924423Z",
          "iopub.execute_input": "2021-06-10T17:25:02.924718Z",
          "iopub.status.idle": "2021-06-10T17:25:02.966959Z",
          "shell.execute_reply.started": "2021-06-10T17:25:02.924693Z",
          "shell.execute_reply": "2021-06-10T17:25:02.966093Z"
        },
        "trusted": true,
        "id": "P-3FboCpQNlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coauthor_nodes=list(coauthor_subgraph.nodes)\n",
        "print(\"Number of CoAuthor Subgraph Nodes\",len(coauthor_nodes))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T16:18:51.602891Z",
          "iopub.execute_input": "2021-06-10T16:18:51.603225Z",
          "iopub.status.idle": "2021-06-10T16:18:51.646849Z",
          "shell.execute_reply.started": "2021-06-10T16:18:51.603182Z",
          "shell.execute_reply": "2021-06-10T16:18:51.645974Z"
        },
        "trusted": true,
        "id": "BoqRtzCcQNlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coauthor_embeddings=[deepwalk_model.wv[node] for node in coauthor_nodes]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T16:18:59.547592Z",
          "iopub.execute_input": "2021-06-10T16:18:59.547913Z",
          "iopub.status.idle": "2021-06-10T16:18:59.592644Z",
          "shell.execute_reply.started": "2021-06-10T16:18:59.547885Z",
          "shell.execute_reply": "2021-06-10T16:18:59.591744Z"
        },
        "trusted": true,
        "id": "_avB1cP8QNlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coauthor_embeddings=np.asarray(coauthor_embeddings)\n",
        "\n",
        "print(coauthor_embeddings.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T16:19:00.426487Z",
          "iopub.execute_input": "2021-06-10T16:19:00.426769Z",
          "iopub.status.idle": "2021-06-10T16:19:00.46783Z",
          "shell.execute_reply.started": "2021-06-10T16:19:00.426745Z",
          "shell.execute_reply": "2021-06-10T16:19:00.46686Z"
        },
        "trusted": true,
        "id": "MeKYkHLTQNlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_dist=getCosineDistanceMatrix(coauthor_embeddings)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T17:25:09.591781Z",
          "iopub.execute_input": "2021-06-10T17:25:09.59207Z",
          "iopub.status.idle": "2021-06-10T17:25:09.639091Z",
          "shell.execute_reply.started": "2021-06-10T17:25:09.592045Z",
          "shell.execute_reply": "2021-06-10T17:25:09.637454Z"
        },
        "trusted": true,
        "id": "8QBhkhgUQNls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### APply K-Means tp select the optimal number of clusters"
      ],
      "metadata": {
        "id": "YcQvBpkVQNls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sse=[]\n",
        "k_list=[]\n",
        "for k in range(2,20):\n",
        "\n",
        "    km=KMeans(n_clusters=k)\n",
        "    km.fit(cosine_dist)\n",
        "    sse.append(km.inertia_)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T17:25:28.527408Z",
          "iopub.execute_input": "2021-06-10T17:25:28.527716Z",
          "iopub.status.idle": "2021-06-10T17:25:56.085718Z",
          "shell.execute_reply.started": "2021-06-10T17:25:28.527679Z",
          "shell.execute_reply": "2021-06-10T17:25:56.084588Z"
        },
        "trusted": true,
        "id": "e_l1VqDVQNls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.plot([i for i in range(2,20)],sse)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T17:25:56.093424Z",
          "iopub.execute_input": "2021-06-10T17:25:56.093902Z",
          "iopub.status.idle": "2021-06-10T17:25:56.318367Z",
          "shell.execute_reply.started": "2021-06-10T17:25:56.093858Z",
          "shell.execute_reply": "2021-06-10T17:25:56.317406Z"
        },
        "trusted": true,
        "id": "4kRxe8UDQNls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets pick 7 clusters and update Node Attribute of the coAuthor Subgraph"
      ],
      "metadata": {
        "id": "-KtFt2tYQNls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "km=KMeans(n_clusters=7)\n",
        "coauthor_clusters=km.fit_predict(cosine_dist)\n",
        "coauthor_cluster_dict={node:str(coauthor_clusters[idx]) for idx,node in enumerate(coauthor_nodes)}\n",
        "nx.set_node_attributes(coauthor_subgraph,coauthor_cluster_dict,\"group\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T17:25:56.319805Z",
          "iopub.execute_input": "2021-06-10T17:25:56.320081Z",
          "iopub.status.idle": "2021-06-10T17:25:57.515141Z",
          "shell.execute_reply.started": "2021-06-10T17:25:56.320053Z",
          "shell.execute_reply": "2021-06-10T17:25:57.513841Z"
        },
        "trusted": true,
        "id": "N6OUn4vKQNls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyvis_nt=Network(notebook=True,height='600px', width='100%',heading='Author Network')\n",
        "\n",
        "print(\"Creating PyVis from NetworkX\")\n",
        "pyvis_nt.from_nx(coauthor_subgraph)\n",
        "pyvis_nt.toggle_physics(True)\n",
        "print(\"Saving PyVis Graph\")\n",
        "#pyvis_nt.show_buttons()\n",
        "#pyvis_nt.set_options('var options = {\"edges\": { \"color\": { \"inherit\": true },\"smooth\": false},\"physics\": {\"hierarchicalRepulsion\": { \"centralGravity\": 0 },\"minVelocity\": 0.75, \"solver\": \"hierarchicalRepulsion\",\"timestep\": 0.18}}')\n",
        "\n",
        "\n",
        "pyvis_nt.show(\"Author4to10_CoAuthorGraph_Clustered.html\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T17:41:31.7022Z",
          "iopub.execute_input": "2021-06-10T17:41:31.702569Z",
          "iopub.status.idle": "2021-06-10T17:41:33.730426Z",
          "shell.execute_reply.started": "2021-06-10T17:41:31.702535Z",
          "shell.execute_reply": "2021-06-10T17:41:33.729467Z"
        },
        "trusted": true,
        "id": "u1CNhHlNQNls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the embeddings has done a pretty good job at clustering the network.\n",
        "\n",
        "### Visualising Bengio Yoshuas Network"
      ],
      "metadata": {
        "id": "Ado70jP2QNls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bengio_nodes=getCoAuthorshipNetwork(G,['Bengio Yoshua'])\n",
        "bengio_network=nx.subgraph(G,bengio_nodes)\n",
        "print(\"Number of Nodes in Bengio Network \",len(bengio_network.nodes()))\n",
        "print(\"Number of Edges in Bengio Network \",len(bengio_network.edges()))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T16:31:03.552256Z",
          "iopub.execute_input": "2021-06-10T16:31:03.552573Z",
          "iopub.status.idle": "2021-06-10T16:31:03.605299Z",
          "shell.execute_reply.started": "2021-06-10T16:31:03.55254Z",
          "shell.execute_reply": "2021-06-10T16:31:03.604045Z"
        },
        "trusted": true,
        "id": "l7JQX_DcQNls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bengio_nt=Network(notebook=True,height='800px', width='100%',heading='Bengio Network')\n",
        "\n",
        "print(\"Creating PyVis from NetworkX\")\n",
        "bengio_nt.from_nx(bengio_network)\n",
        "bengio_nt.toggle_physics(True)\n",
        "#bengio_nt.enable_physics(True)\n",
        "print(\"Saving PyVis Graph\")\n",
        "\n",
        "bengio_nt.show_buttons()\n",
        "bengio_nt.show(\"Bengio_CoAuthorGraph.html\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-10T16:47:42.590707Z",
          "iopub.execute_input": "2021-06-10T16:47:42.59105Z",
          "iopub.status.idle": "2021-06-10T16:47:43.021468Z",
          "shell.execute_reply.started": "2021-06-10T16:47:42.591018Z",
          "shell.execute_reply": "2021-06-10T16:47:43.020568Z"
        },
        "trusted": true,
        "id": "ep6iN4ruQNls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C6OkWyd4QNls"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}