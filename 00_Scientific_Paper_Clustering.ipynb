{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDSl54rks-yz"
      },
      "source": [
        "# Goal of this Project\n",
        "\n",
        "The goal of this project is to cluster scientifical papers based on theirs abstract with unsupervised ML methods.\n",
        "\n",
        "By using clustering for labelling in combination with dimensionality reduction for visualization, the collection of papers can be represented as a scatter plot. On this plot, papers of highly similar topics will share a label and will be plotted near each other. As a bonus (if clustering works well) I try to find meaning in the clusters by using topic modelling to find the keywords of each cluster.\n",
        "This can help to find publications with similar research backgrounds and to compare similar research and publications.\n",
        "\n",
        "The data must be prepared accordingly so that they can be processed with a clustering model.\n",
        "I use NLP (Natural Language Processing) to prepare the data. With this notebook I also want to test how certain preprocessing steps affect the quality of the clusters (stops word removing, handling different languages, different vectorization strategies).\n",
        "\n",
        "This project will be done with the [arXiv Dataset](https://www.kaggle.com/Cornell-University/arxiv) featured on kaggle.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiNJfDSXs-y0"
      },
      "source": [
        "# Approach:\n",
        "\n",
        "- Load data\n",
        "- Parse the text from the abstract of each document using Natural Language Processing (NLP).\n",
        "- Turn each abstract into a feature vector using Term Frequency–inverse Document Frequency (TF-IDF).\n",
        "- Use Principal Component Analysis (PCA) for dimensionality reduction\n",
        "- Apply Dimensionality Reduction to each feature vector using t-Distributed Stochastic Neighbor Embedding (t-SNE) and umap.\n",
        "- Apply k-means clustering\n",
        "- Visualize clusters as a (interactive) scatterplot\n",
        "- **Bonus:** Apply Topic Modeling for each cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISkftUhks-y0"
      },
      "source": [
        "Content:\n",
        "1. Load data\n",
        "2. Short EDA and some basic data-cleaning / feature engineering\n",
        "3. NLP data preprocessing\n",
        "4. Vectorization of the abstracts and dimensionality reduction with PCA\n",
        "5. Clustering\n",
        "6. t-SNE and umap (Using umap to see difference to t-SNE)\n",
        "7. Compare t-SNE and umap\n",
        "8. Plots an interactive scatter plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXo0S6_Xs-y0"
      },
      "source": [
        "### About the ArXiv dataset:\n",
        "> For nearly 30 years, ArXiv has served the public and research communities by providing open access to scholarly articles, from the vast branches of physics to the many subdisciplines of computer science to everything in between, including math, statistics, electrical engineering, quantitative biology, and economics. This rich corpus of information offers significant, but sometimes overwhelming depth.\n",
        "In these times of unique global challenges, efficient extraction of insights from data is essential. To help make the arXiv more accessible, we present a free, open pipeline on Kaggle to the machine-readable arXiv dataset: a repository of 1.7 million articles, with relevant features such as article titles, authors, categories, abstracts, full text PDFs, and more.\n",
        "Our hope is to empower new use cases that can lead to the exploration of richer machine learning techniques that combine multi-modal features towards applications like trend analysis, paper recommender engines, category prediction, co-citation networks, knowledge graph construction and semantic search interfaces.\n",
        "\n",
        ">#### Cite: https://www.kaggle.com/Cornell-University/arxiv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU0tqGyCs-y0"
      },
      "source": [
        "# Load the data\n",
        "If the whole dataset is to be loaded, it is recommended in the footnote of the dataset to load the dataset with the library [dask](http://dask.org).\n",
        "Dask makes it possible to load lager datasets an process large amount of data on personal computers or VM's with limited resources\n",
        "\n",
        "About dask:\n",
        "\n",
        "> Dask is a flexible library for parallel computing in Python.\n",
        "\n",
        "> From dask.org"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1tT7A2dZs-y0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logger = logging.getLogger(\"spacy\")\n",
        "logger.setLevel(logging.ERROR)\n",
        "\n",
        "import dask.bag as db\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "docs = db.read_text('./arxiv/arxiv-metadata-oai-snapshot.json').map(json.loads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vAnX_odls-y0",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2426574"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Total number of documents: 1872765\n",
        "docs.count().compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gH06XebEs-y0",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'id': '0704.0001',\n",
              "  'submitter': 'Pavel Nadolsky',\n",
              "  'authors': \"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\",\n",
              "  'title': 'Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies',\n",
              "  'comments': '37 pages, 15 figures; published version',\n",
              "  'journal-ref': 'Phys.Rev.D76:013009,2007',\n",
              "  'doi': '10.1103/PhysRevD.76.013009',\n",
              "  'report-no': 'ANL-HEP-PR-07-12',\n",
              "  'categories': 'hep-ph',\n",
              "  'license': None,\n",
              "  'abstract': '  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n',\n",
              "  'versions': [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 19:18:42 GMT'},\n",
              "   {'version': 'v2', 'created': 'Tue, 24 Jul 2007 20:10:27 GMT'}],\n",
              "  'update_date': '2008-11-26',\n",
              "  'authors_parsed': [['Balázs', 'C.', ''],\n",
              "   ['Berger', 'E. L.', ''],\n",
              "   ['Nadolsky', 'P. M.', ''],\n",
              "   ['Yuan', 'C. -P.', '']]},)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Looking at one document:\n",
        "docs.take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fDIZDq4Ds-y1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# The dataset is very huge. Not sure if the whole set can be used. I start prototyping with a subset of the data so it's easyer to handel:\n",
        "# This procedure was recommended in the ArXiv dataset itself\n",
        "\n",
        "get_latest_version = lambda x: x['versions'][-1]['created']\n",
        "\n",
        "\n",
        "# get only necessary fields of the metadata file\n",
        "trim = lambda x: {'id': x['id'],\n",
        "                  'authors': x['authors'],\n",
        "                  'title': x['title'],\n",
        "                  'doi': x['doi'],\n",
        "                  'category':x['categories'].split(' '),\n",
        "                  'abstract':x['abstract'],}\n",
        "# filter for papers published on or after 2019-01-01\n",
        "columns = ['id','category','abstract']\n",
        "docs_df = (docs.filter(lambda x: int(get_latest_version(x).split(' ')[3]) > 2018)\n",
        "           .map(trim).\n",
        "           compute())\n",
        "\n",
        "# convert to pandas\n",
        "docs_df = pd.DataFrame(docs_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-KO8SIm2s-y1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#save trimmed dataset for later use so we can skip the dataset trimming later:\n",
        "docs_df.to_csv(\"trimmed_arxiv_docs.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zLKQT43Zs-y1",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>authors</th>\n",
              "      <th>title</th>\n",
              "      <th>doi</th>\n",
              "      <th>category</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0704.0033</td>\n",
              "      <td>Maxim A. Yurkin, Valeri P. Maltsev, Alfons G. ...</td>\n",
              "      <td>Convergence of the discrete dipole approximati...</td>\n",
              "      <td>10.1364/JOSAA.23.002578 10.1364/JOSAA.32.002407</td>\n",
              "      <td>[physics.optics, physics.comp-ph]</td>\n",
              "      <td>We performed a rigorous theoretical converge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0704.0038</td>\n",
              "      <td>Maxim A. Yurkin, Alfons G. Hoekstra</td>\n",
              "      <td>The discrete dipole approximation: an overview...</td>\n",
              "      <td>10.1016/j.jqsrt.2007.01.034 10.1016/j.jqsrt.20...</td>\n",
              "      <td>[physics.optics, physics.comp-ph]</td>\n",
              "      <td>We present a review of the discrete dipole a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0704.0479</td>\n",
              "      <td>T.Geisser</td>\n",
              "      <td>The affine part of the Picard scheme</td>\n",
              "      <td>None</td>\n",
              "      <td>[math.AG, math.KT]</td>\n",
              "      <td>We describe the maximal torus and maximal un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0704.1445</td>\n",
              "      <td>Yasha Gindikin and Vladimir A. Sablikov</td>\n",
              "      <td>Deformed Wigner crystal in a one-dimensional q...</td>\n",
              "      <td>10.1103/PhysRevB.76.045122</td>\n",
              "      <td>[cond-mat.str-el, cond-mat.mes-hall]</td>\n",
              "      <td>The spatial Fourier spectrum of the electron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0704.1476</td>\n",
              "      <td>Chris Austin</td>\n",
              "      <td>TeV-scale gravity in Horava-Witten theory on a...</td>\n",
              "      <td>None</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>The field equations and boundary conditions ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                            authors  \\\n",
              "0  0704.0033  Maxim A. Yurkin, Valeri P. Maltsev, Alfons G. ...   \n",
              "1  0704.0038                Maxim A. Yurkin, Alfons G. Hoekstra   \n",
              "2  0704.0479                                          T.Geisser   \n",
              "3  0704.1445            Yasha Gindikin and Vladimir A. Sablikov   \n",
              "4  0704.1476                                       Chris Austin   \n",
              "\n",
              "                                               title  \\\n",
              "0  Convergence of the discrete dipole approximati...   \n",
              "1  The discrete dipole approximation: an overview...   \n",
              "2               The affine part of the Picard scheme   \n",
              "3  Deformed Wigner crystal in a one-dimensional q...   \n",
              "4  TeV-scale gravity in Horava-Witten theory on a...   \n",
              "\n",
              "                                                 doi  \\\n",
              "0    10.1364/JOSAA.23.002578 10.1364/JOSAA.32.002407   \n",
              "1  10.1016/j.jqsrt.2007.01.034 10.1016/j.jqsrt.20...   \n",
              "2                                               None   \n",
              "3                         10.1103/PhysRevB.76.045122   \n",
              "4                                               None   \n",
              "\n",
              "                               category  \\\n",
              "0     [physics.optics, physics.comp-ph]   \n",
              "1     [physics.optics, physics.comp-ph]   \n",
              "2                    [math.AG, math.KT]   \n",
              "3  [cond-mat.str-el, cond-mat.mes-hall]   \n",
              "4                              [hep-th]   \n",
              "\n",
              "                                            abstract  \n",
              "0    We performed a rigorous theoretical converge...  \n",
              "1    We present a review of the discrete dipole a...  \n",
              "2    We describe the maximal torus and maximal un...  \n",
              "3    The spatial Fourier spectrum of the electron...  \n",
              "4    The field equations and boundary conditions ...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Let's have a look at the first 5 rows:\n",
        "docs_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqlo0QAXs-y1"
      },
      "source": [
        "# Short EDA and some basic data-cleaning / feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LDuSgVtTs-y1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/c0/s3dff31j48j6qs83tjklr6kw0000gn/T/ipykernel_81556/223106121.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"./trimmed_arxiv_docs.csv\")\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"./trimmed_arxiv_docs.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V7AD1TMhs-y1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 992613 entries, 0 to 992612\n",
            "Data columns (total 6 columns):\n",
            " #   Column    Non-Null Count   Dtype \n",
            "---  ------    --------------   ----- \n",
            " 0   id        992613 non-null  object\n",
            " 1   authors   992613 non-null  object\n",
            " 2   title     992613 non-null  object\n",
            " 3   doi       341265 non-null  object\n",
            " 4   category  992613 non-null  object\n",
            " 5   abstract  992613 non-null  object\n",
            "dtypes: object(6)\n",
            "memory usage: 45.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PVmJw7BAs-y2",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(992613, 6)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Jt3C4o8gs-y2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Addint word counts of each abstract could be a usefull feature\n",
        "df['abstract_word_count'] = docs_df['abstract'].apply(lambda x: len(x.strip().split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-9DNkLCds-y2",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count                                                992613\n",
              "unique                                               992424\n",
              "top         arXiv admin note: This submission has been w...\n",
              "freq                                                      3\n",
              "Name: abstract, dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['abstract'].describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RQc-64Dqs-y2",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count                                                992424\n",
              "unique                                               992424\n",
              "top         We performed a rigorous theoretical converge...\n",
              "freq                                                      1\n",
              "Name: abstract, dtype: object"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#There are duplicated abstracts, would be the best to get rid of these\n",
        "df.drop_duplicates(['abstract',], inplace=True)\n",
        "df['abstract'].describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIlJ05CHs-y2"
      },
      "source": [
        "The raw text of the abstracts can't be processed by a model. Next step now is to transform the data in two steps:\n",
        "\n",
        "- Use NLP to restructur the abstract text --> Remove Stop words an punctuation\n",
        "- Vectorize the abstact's of each paper\n",
        "\n",
        "The NLP wasn't cover in the course. Most of the strategies use in the next steps are based on the kaggle NLP Course https://www.kaggle.com/learn/natural-language-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxWvZY27s-y2"
      },
      "source": [
        "# NLP data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QB8c4r5Ms-y2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# the dataframe contains still hugh amount of data. The process the data faster I reduce the df to 10000 rows\n",
        "# The scope of the notebook is not to analyze all data\n",
        "df = df.sample(10000, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GBbTHSn_s-y2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "# I discoverd that it's possible to download models for the specific purpose to preprocess scientific texts\n",
        "# In the spacy docs I found a specific model for this : https://spacy.io/universe/project/scispacy\n",
        "#Downloading en_core_sci_lg model to preprocess abstracts\n",
        "from IPython.utils import io\n",
        "with io.capture_output() as captured:\n",
        "    !pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_core_sci_lg-0.4.0.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_core_sci_lg-0.4.0.tar.gz\n",
            "  Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_core_sci_lg-0.4.0.tar.gz (538.1 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.1 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from en-core-sci-lg==0.4.0) (3.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (3.0.12)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (0.7.11)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (0.3.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (4.66.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (1.24.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (68.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (23.2)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (2.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (2024.2.2)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from jinja2->spacy<3.1.0,>=3.0.1->en-core-sci-lg==0.4.0) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_core_sci_lg-0.4.0.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "azLOFBOKs-y2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Import NLP librarys and the spacy package to preprocess the abstract text\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS #import commen list of stopword\n",
        "import en_core_sci_lg  # import downlaoded model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0LMY3trTs-y2",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "issubclass() arg 1 must be a class",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Parser\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43men_core_sci_lg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m parser\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7000000\u001b[39m \u001b[38;5;66;03m#Limit the size of the parser\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspacy_tokenizer\u001b[39m(sentence):\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/en_core_sci_lg/__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_init_py\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/spacy/util.py:517\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE052\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mdata_path))\n\u001b[0;32m--> 517\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/spacy/util.py:392\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    390\u001b[0m overrides \u001b[38;5;241m=\u001b[39m dict_to_dot(config)\n\u001b[1;32m    391\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config(config_path, overrides\u001b[38;5;241m=\u001b[39moverrides)\n\u001b[0;32m--> 392\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mfrom_disk(model_path, exclude\u001b[38;5;241m=\u001b[39mexclude, overrides\u001b[38;5;241m=\u001b[39moverrides)\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/spacy/util.py:429\u001b[0m, in \u001b[0;36mload_model_from_config\u001b[0;34m(config, vocab, disable, exclude, auto_fill, validate)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# This will automatically handle all codes registered via the languages\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# registry, including custom subclasses provided via entry points\u001b[39;00m\n\u001b[1;32m    428\u001b[0m lang_cls \u001b[38;5;241m=\u001b[39m get_lang_class(nlp_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 429\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mlang_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_fill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nlp\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/spacy/language.py:1672\u001b[0m, in \u001b[0;36mLanguage.from_config\u001b[0;34m(cls, config, vocab, disable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[1;32m   1669\u001b[0m     factory \u001b[38;5;241m=\u001b[39m pipe_cfg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfactory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1670\u001b[0m     \u001b[38;5;66;03m# The pipe name (key in the config) here is the unique name\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m     \u001b[38;5;66;03m# of the component, not necessarily the factory\u001b[39;00m\n\u001b[0;32m-> 1672\u001b[0m     \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_pipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfactory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipe_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipe_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1680\u001b[0m     model \u001b[38;5;241m=\u001b[39m pipe_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/spacy/language.py:774\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_factory(factory_name):\n\u001b[1;32m    767\u001b[0m         err \u001b[38;5;241m=\u001b[39m Errors\u001b[38;5;241m.\u001b[39mE002\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    768\u001b[0m             name\u001b[38;5;241m=\u001b[39mfactory_name,\n\u001b[1;32m    769\u001b[0m             opts\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfactory_names),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    772\u001b[0m             lang_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang,\n\u001b[1;32m    773\u001b[0m         )\n\u001b[0;32m--> 774\u001b[0m     pipe_component \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_pipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfactory_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m pipe_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pipe_index(before, after, first, last)\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipe_meta[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_factory_meta(factory_name)\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/spacy/language.py:660\u001b[0m, in \u001b[0;36mLanguage.create_pipe\u001b[0;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    657\u001b[0m cfg \u001b[38;5;241m=\u001b[39m {factory_name: config}\n\u001b[1;32m    658\u001b[0m \u001b[38;5;66;03m# We're calling the internal _fill here to avoid constructing the\u001b[39;00m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;66;03m# registered functions twice\u001b[39;00m\n\u001b[0;32m--> 660\u001b[0m resolved \u001b[38;5;241m=\u001b[39m \u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m filled \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mfill({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfg\u001b[39m\u001b[38;5;124m\"\u001b[39m: cfg[factory_name]}, validate\u001b[38;5;241m=\u001b[39mvalidate)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfg\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    662\u001b[0m filled \u001b[38;5;241m=\u001b[39m Config(filled)\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/thinc/config.py:746\u001b[0m, in \u001b[0;36mregistry.resolve\u001b[0;34m(cls, config, schema, overrides, validate)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresolve\u001b[39m(\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    744\u001b[0m     validate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    745\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m--> 746\u001b[0m     resolved, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resolved\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/thinc/config.py:795\u001b[0m, in \u001b[0;36mregistry._make\u001b[0;34m(cls, config, schema, overrides, resolve, validate)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interpolated:\n\u001b[1;32m    794\u001b[0m     config \u001b[38;5;241m=\u001b[39m Config(orig_config)\u001b[38;5;241m.\u001b[39minterpolate()\n\u001b[0;32m--> 795\u001b[0m filled, _, resolved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fill\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolve\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m filled \u001b[38;5;241m=\u001b[39m Config(filled, section_order\u001b[38;5;241m=\u001b[39msection_order)\n\u001b[1;32m    799\u001b[0m \u001b[38;5;66;03m# Check that overrides didn't include invalid properties not in config\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/thinc/config.py:850\u001b[0m, in \u001b[0;36mregistry._fill\u001b[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[1;32m    848\u001b[0m     schema\u001b[38;5;241m.\u001b[39m__fields__[key] \u001b[38;5;241m=\u001b[39m copy_model_field(field, Any)\n\u001b[1;32m    849\u001b[0m promise_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmake_promise_schema(value, resolve\u001b[38;5;241m=\u001b[39mresolve)\n\u001b[0;32m--> 850\u001b[0m filled[key], validation[v_key], final[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fill\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpromise_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolve\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_parent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    858\u001b[0m reg_name, func_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_constructor(final[key])\n\u001b[1;32m    859\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mparse_args(final[key])\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/thinc/config.py:849\u001b[0m, in \u001b[0;36mregistry._fill\u001b[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[1;32m    847\u001b[0m     field \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39m__fields__[key]\n\u001b[1;32m    848\u001b[0m     schema\u001b[38;5;241m.\u001b[39m__fields__[key] \u001b[38;5;241m=\u001b[39m copy_model_field(field, Any)\n\u001b[0;32m--> 849\u001b[0m promise_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_promise_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m filled[key], validation[v_key], final[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_fill(\n\u001b[1;32m    851\u001b[0m     value,\n\u001b[1;32m    852\u001b[0m     promise_schema,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    856\u001b[0m     overrides\u001b[38;5;241m=\u001b[39moverrides,\n\u001b[1;32m    857\u001b[0m )\n\u001b[1;32m    858\u001b[0m reg_name, func_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_constructor(final[key])\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/thinc/config.py:1057\u001b[0m, in \u001b[0;36mregistry.make_promise_schema\u001b[0;34m(cls, obj, resolve)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         sig_args[name] \u001b[38;5;241m=\u001b[39m (annotation, default)\n\u001b[1;32m   1056\u001b[0m sig_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__config__\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _PromiseSchemaConfig\n\u001b[0;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mArgModel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msig_args\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/pydantic/main.py:990\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(__model_name, __config__, __base__, __module__, __validators__, **field_definitions)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m __config__:\n\u001b[1;32m    988\u001b[0m     namespace[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfig\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m inherit_config(__config__, BaseConfig)\n\u001b[0;32m--> 990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m__model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m__base__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/pydantic/main.py:299\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[0;34m(mcs, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    292\u001b[0m         is_untouched(value)\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m ann_type \u001b[38;5;241m!=\u001b[39m PyObject\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         )\n\u001b[1;32m    297\u001b[0m     ):\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m     fields[ann_name] \u001b[38;5;241m=\u001b[39m \u001b[43mModelField\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mann_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mannotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mann_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_validators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_validators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mann_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ann_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m namespace \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39munderscore_attrs_are_private:\n\u001b[1;32m    307\u001b[0m     private_attributes[ann_name] \u001b[38;5;241m=\u001b[39m PrivateAttr()\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/pydantic/fields.py:411\u001b[0m, in \u001b[0;36mModelField.infer\u001b[0;34m(cls, name, value, annotation, class_validators, config)\u001b[0m\n\u001b[1;32m    409\u001b[0m     required \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    410\u001b[0m annotation \u001b[38;5;241m=\u001b[39m get_annotation_from_field_info(annotation, field_info, name, config\u001b[38;5;241m.\u001b[39mvalidate_assignment)\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43malias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_validators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_validators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequired\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequired\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/pydantic/fields.py:342\u001b[0m, in \u001b[0;36mModelField.__init__\u001b[0;34m(self, name, type_, class_validators, model_config, default, default_factory, required, alias, field_info)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m SHAPE_SINGLETON\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mprepare_field(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 342\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/pydantic/fields.py:451\u001b[0m, in \u001b[0;36mModelField.prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m ForwardRef \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m DeferredType:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;66;03m# self.type_ is currently a ForwardRef and there's nothing we can do now,\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# user will need to call model.update_forward_refs()\u001b[39;00m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_type_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequired \u001b[38;5;129;01mis\u001b[39;00m Undefined:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequired \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/pydantic/fields.py:550\u001b[0m, in \u001b[0;36mModelField._type_analysis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msub_fields \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_sub_type(t, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_as_type(t)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types_]\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43missubclass\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTuple\u001b[49m\u001b[43m)\u001b[49m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;66;03m# origin == Tuple without item type\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     args \u001b[38;5;241m=\u001b[39m get_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_)\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:  \u001b[38;5;66;03m# plain tuple\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/typing.py:852\u001b[0m, in \u001b[0;36m_SpecialGenericAlias.__subclasscheck__\u001b[0;34m(self, cls)\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__origin__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__origin__)\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m, _GenericAlias):\n\u001b[0;32m--> 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43missubclass\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__origin__\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__subclasscheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n",
            "\u001b[0;31mTypeError\u001b[0m: issubclass() arg 1 must be a class"
          ]
        }
      ],
      "source": [
        "# Parser\n",
        "parser = en_core_sci_lg.load()\n",
        "parser.max_length = 7000000 #Limit the size of the parser\n",
        "\n",
        "def spacy_tokenizer(sentence):\n",
        "    ''' Function to preprocess text of scientific papers\n",
        "        (e.g Removing Stopword and puntuations)'''\n",
        "    mytokens = parser(sentence)\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ] # transform to lowercase and then split the scentence\n",
        "    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ] #remove stopsword an punctuation\n",
        "    mytokens = \" \".join([i for i in mytokens])\n",
        "    return mytokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oUE55Uuqs-y2",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['side',\n",
              " 'toward',\n",
              " 'around',\n",
              " 'amongst',\n",
              " 'almost',\n",
              " 'made',\n",
              " 'cannot',\n",
              " 'being',\n",
              " 'does',\n",
              " 'down']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import string\n",
        "\n",
        "punctuations = string.punctuation #list of punctuation to remove from text\n",
        "stopwords = list(STOP_WORDS)\n",
        "stopwords[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4mbuBzVs-y2"
      },
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JaPU0MD7s-y2",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'spacy_tokenizer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas()\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed_text\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabstract\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mprogress_apply(\u001b[43mspacy_tokenizer\u001b[49m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'spacy_tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "tqdm.pandas()\n",
        "df[\"processed_text\"] = df[\"abstract\"].progress_apply(spacy_tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmYGS75Qs-y3"
      },
      "source": [
        "# Vectorization of the abstracts and dimensionality reduction with PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GldFHAPQs-y3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import vectorizer and define vec function\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "def vectorize(text, maxx_features):\n",
        "\n",
        "    vectorizer = TfidfVectorizer(max_features=maxx_features)\n",
        "    X = vectorizer.fit_transform(text)\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw1sY4IUs-y3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#vectorize each processed abstract\n",
        "text = df['processed_text'].values\n",
        "X = vectorize(text, 2 ** 12) #arbitrary max feature -_> Hyperpara. for optimisation (?)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8gX8EFss-y3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.95, random_state=42) #Keep 95% of the variance\n",
        "X_reduced= pca.fit_transform(X.toarray())\n",
        "X_reduced.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_CdqNias-y3"
      },
      "source": [
        "# Clustering\n",
        "\n",
        "Using Kmeans for Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZSqfty9s-y3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUvcjbGCs-y3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# find optimal k value\n",
        "#r_seed = 24\n",
        "#cluster_errors = []\n",
        "\n",
        "#for i in range(1, 50):\n",
        "    #n_clusters = i\n",
        "    #pipe_pca_kmean = Pipeline([(\"cluster\", KMeans(n_clusters=n_clusters, random_state=r_seed, verbose=0, n_jobs=1))]\n",
        "    #)\n",
        "\n",
        "    #pipe_pca_kmean.fit(X_reduced)\n",
        "    #pipe_pca_kmean.predict(X_reduced)\n",
        "    #cluster_errors.append(pipe_pca_kmean.named_steps[\"cluster\"].inertia_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BybUJbWs-y3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#plt.clf()\n",
        "#plt.plot(cluster_errors, \"o-\")\n",
        "#plt.xlabel(\"k_clusters\")\n",
        "#plt.ylabel(\"sum sq distances from mean\")\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfqSC-lus-y3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "k = 20 # optimal k found in elbow plot\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "y_pred = kmeans.fit_predict(X_reduced)\n",
        "df['kmean_clusters'] = y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSb30W1ks-y3"
      },
      "source": [
        "# t-SNE and umap (Using umap to see difference to t-SNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lCNuUk9s-y3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-0p77Eks-y4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from umap import UMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZddCFqbZs-y4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# UMAP Definition:\n",
        "umap_embeddings = UMAP(n_neighbors=100, min_dist=0.3, n_components=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdmFHAf4s-y4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "X_umap = umap_embeddings.fit_transform(X_reduced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycvrrB5gs-y4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tsne = TSNE(verbose=1, perplexity=100, random_state=42)\n",
        "X_embedded = tsne.fit_transform(X.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuWaJua9s-y4"
      },
      "source": [
        "# Compare t-SNE and umap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lay0D3qRs-y4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# sns settings\n",
        "sns.set(rc={'figure.figsize':(15,15)})\n",
        "\n",
        "# colors\n",
        "palette = sns.color_palette(\"bright\", 1)\n",
        "\n",
        "# plot\n",
        "sns.scatterplot(x=X_embedded[:,0], y=X_embedded[:,1], palette=palette)\n",
        "plt.title('t-SNE without Labels')\n",
        "plt.savefig(\"t-sne_arxvid.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-BeFKYAs-y4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# sns settings\n",
        "sns.set(rc={'figure.figsize':(15,15)})\n",
        "\n",
        "# colors\n",
        "palette = sns.color_palette(\"bright\", 1)\n",
        "\n",
        "# plot\n",
        "sns.scatterplot(x=X_umap[:,0], y=X_umap[:,1], palette=palette)\n",
        "plt.title('umap without Labels')\n",
        "plt.savefig(\"umap_arxvid.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucNRWjMOs-y5"
      },
      "source": [
        "# Plot Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qxf4yxdgs-y5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# sns settings\n",
        "sns.set(rc={'figure.figsize':(15,15)})\n",
        "\n",
        "# colors\n",
        "palette = sns.hls_palette(20, l=.4, s=.9)\n",
        "\n",
        "# plot\n",
        "sns.scatterplot(x=X_embedded[:,0], y=X_embedded[:,1], hue=y_pred, legend='full', palette=palette)\n",
        "plt.title('t-SNE with Kmeans Labels')\n",
        "plt.savefig(\"cluster_tsne.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjwnjrRPs-y5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# sns settings\n",
        "sns.set(rc={'figure.figsize':(15,15)})\n",
        "\n",
        "# colors\n",
        "palette = sns.hls_palette(20, l=.4, s=.9)\n",
        "\n",
        "# plot\n",
        "sns.scatterplot(x=X_umap[:,0], y=X_umap[:,1], hue=y_pred, legend='full', palette=palette)\n",
        "plt.title('umap with Kmeans Labels')\n",
        "plt.savefig(\"cluster_umap_kmeans_labels.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrdQRyXws-y5"
      },
      "source": [
        "The labeled plot gives insights of how the papers are grouped.\n",
        "It is difficult to say which dimension reduction performs better for this data. The performance would have to be evaluated in further steps.\n",
        "\n",
        "The location of each paper on the plot was determined by umap / t-SNE while the labels (colors) was determined by k-means.\n",
        "If we look at a particular parts of the plots where t-SNE and umap have grouped many articles forming a cluster, it is likely that k-means is uniform in the labeling of this cluster.\n",
        "\n",
        "In other cases the labels (k-means) are more spread out on the plot (umap /t-SNE). This means that umap / t-SNE and k-means found differences in the higher dimensional data.\n",
        "\n",
        "This could be because certain contents in the papers overlaping, so it's hard to clearly separate them. This effect can be observed in the formation of subclusters on the plot.\n",
        "\n",
        "The algorithms may find connections that were unnaparent to humans. This may highlight hidden shared information and advance further research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdUm0LTQs-y5"
      },
      "source": [
        "# Plot interactive scatter plot bases on t-SNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT2jRkzFs-y5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "fig = px.scatter(df, x=X_embedded[:,0], y=X_embedded[:,1], color=y_pred.astype(str),\n",
        "                 hover_data=['id', 'authors', 'title',],\n",
        "                 height= 1000, width=1000,\n",
        "                title = \"t-SNE with Kmeans Labels\")\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Scientific Paper Clustering",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
