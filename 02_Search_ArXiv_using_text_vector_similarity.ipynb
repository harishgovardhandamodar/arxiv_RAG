{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 7694881,
          "sourceType": "datasetVersion",
          "datasetId": 612177
        },
        {
          "sourceId": 164070052,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30648,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Part 2 - Search ArXiv using text vector similarity",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'arxiv:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F612177%2F7694881%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240229%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240229T132857Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Db4150aa6cbda2a3b243e138918c772590871977b5f460dc6e840965e651f040a64c4c79960012e21dfafe4d7eac6800777e7037b96e0526bfaf7f4298f0f94884bc3209576d232ff161ca2986c1dbaceb7bf04159341eec89416906c7b4c4398f46035a791c70fb65a7fd884791ab4b336eee08466fdd7deb435342cfa318880f8c093d82199a13ffa71c479b3b5469bb6cdba82646b8beef8cde8535cabdf67497515e7dd1b6a34b89e975bada004e468750e01d8c11e6b453495508daa7147ba4973aac7a6dd9f7353c41c0b42e8cf0bd8e5c2b159f0b928f8d5f8d39cef332416e87b27e8f9348591ea2fb883045dea180fbfe30e1f4cfb0c4a0136f9b444'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "h5fCLI6UDdTu"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "YULvRRKIDdTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 2 - Search for ArXiv papers using text vector similarity\n",
        "Use natural language to search for research papers on ArXiv and<br>\n",
        "get search results in a format that enables quick review.<br>\n",
        "by vbookshelf<br>\n",
        "20 Feb 2024"
      ],
      "metadata": {
        "id": "9UAkUfrIDdTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1 - Build an ArXiv RAG search system w FAISS<br>\n",
        "https://www.kaggle.com/code/vbookshelf/part-1-build-an-arxiv-rag-search-system-w-faiss"
      ],
      "metadata": {
        "id": "woP66PYWDdTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In Part 1 we built a RAG search system that allows us to use natural language to search for ArXiv research papers. In this notebook you can submit search queries and review the results.\n",
        "\n",
        "We will be running a FAISS exhaustive (brute-force) search. Normally a nearest neigbors search would be used because it's faster. But I found that, even with more that 2.4 million vectors, a FAISS exhaustive search is still very fast.\n",
        "\n",
        "Here we won't be using OpenAi to generate a natural language output because in this context that feature doesn't add alot of value.\n",
        "\n",
        "## How to run a search\n",
        "\n",
        "To run a search you'll need to \"Copy and edit\" this notebook. Then run each cell.\n",
        "\n",
        "Please ensure that the GPU (P100) is switched on."
      ],
      "metadata": {
        "id": "JJLMBVy0DdTz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cRwbUrR6DdTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install packages"
      ],
      "metadata": {
        "id": "-RRx18WvDdTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-02-29T12:33:50.481889Z",
          "iopub.execute_input": "2024-02-29T12:33:50.48221Z",
          "iopub.status.idle": "2024-02-29T12:34:04.160897Z",
          "shell.execute_reply.started": "2024-02-29T12:33:50.482176Z",
          "shell.execute_reply": "2024-02-29T12:34:04.15999Z"
        },
        "trusted": true,
        "id": "6PvDwWaoDdT0",
        "outputId": "a4367d34-42d4-4512-fbc6-88f757ba0590"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting sentence-transformers\n  Downloading sentence_transformers-2.4.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.37.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.24.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.20.3)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-2.4.0-py3-none-any.whl (149 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.5/149.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.4.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install faiss-cpu\n",
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-02-29T12:34:04.162702Z",
          "iopub.execute_input": "2024-02-29T12:34:04.163005Z",
          "iopub.status.idle": "2024-02-29T12:34:18.955867Z",
          "shell.execute_reply.started": "2024-02-29T12:34:04.162978Z",
          "shell.execute_reply": "2024-02-29T12:34:18.954865Z"
        },
        "trusted": true,
        "id": "6_A-_wyiDdT0",
        "outputId": "97d28c81-35a5-4c17-b228-0b516e36b701"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zhn00zhtDdT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import json\n",
        "import re"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-29T12:34:18.9572Z",
          "iopub.execute_input": "2024-02-29T12:34:18.957543Z",
          "iopub.status.idle": "2024-02-29T12:34:19.314039Z",
          "shell.execute_reply.started": "2024-02-29T12:34:18.957511Z",
          "shell.execute_reply": "2024-02-29T12:34:19.313325Z"
        },
        "trusted": true,
        "id": "T5Fpn_-9DdT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The embeddings and the dataframe created and saved in Part 1\n",
        "\n",
        "PATH_TO_EMBEDS = '../input/part-1-build-an-arxiv-rag-search-system-w-faiss/compressed_array.npz'\n",
        "PATH_TO_DF = '../input/part-1-build-an-arxiv-rag-search-system-w-faiss/compressed_dataframe.csv.gz'\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-29T12:34:19.31609Z",
          "iopub.execute_input": "2024-02-29T12:34:19.316457Z",
          "iopub.status.idle": "2024-02-29T12:34:19.320533Z",
          "shell.execute_reply.started": "2024-02-29T12:34:19.316431Z",
          "shell.execute_reply": "2024-02-29T12:34:19.319631Z"
        },
        "trusted": true,
        "id": "XuM2dQvVDdT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('../input/')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-29T12:34:19.321685Z",
          "iopub.execute_input": "2024-02-29T12:34:19.321976Z",
          "iopub.status.idle": "2024-02-29T12:34:19.333048Z",
          "shell.execute_reply.started": "2024-02-29T12:34:19.321943Z",
          "shell.execute_reply": "2024-02-29T12:34:19.332229Z"
        },
        "trusted": true,
        "id": "iGi9C_pdDdT1",
        "outputId": "d579d5f6-3aae-4c21-9ca4-a925ed8c3484"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['part-1-build-an-arxiv-rag-search-system-w-faiss', 'arxiv']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "ACC2ix2MDdT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_faiss_search(query_text, top_k):\n",
        "\n",
        "    # Run FAISS exhaustive search\n",
        "\n",
        "    query = [query_text]\n",
        "\n",
        "    # Vectorize the query string\n",
        "    query_embedding = model.encode(query)\n",
        "\n",
        "    # Run the query\n",
        "    # index_vals refers to the chunk_list index values\n",
        "    scores, index_vals = faiss_index.search(query_embedding, top_k)\n",
        "\n",
        "    # Get the list of index vals\n",
        "    index_vals_list = index_vals[0]\n",
        "\n",
        "    return index_vals_list\n",
        "\n",
        "\n",
        "def run_rerank(index_vals_list, query_text):\n",
        "\n",
        "    chunk_list = list(df_data['prepared_text'])\n",
        "\n",
        "    # Replace the chunk index values with the corresponding strings\n",
        "    pred_strings_list = [chunk_list[item] for item in index_vals_list]\n",
        "\n",
        "    # Format the input for the cross encoder\n",
        "    # The input to the cross_encoder is a list of lists\n",
        "    # [[query_text, pred_text1], [query_text, pred_text2], ...]\n",
        "\n",
        "    cross_input_list = []\n",
        "\n",
        "    for item in pred_strings_list:\n",
        "\n",
        "        new_list = [query_text, item]\n",
        "\n",
        "        cross_input_list.append(new_list)\n",
        "\n",
        "\n",
        "    # Put the pred text into a dataframe\n",
        "    df = pd.DataFrame(cross_input_list, columns=['query_text', 'pred_text'])\n",
        "\n",
        "    # Save the orginal index (i.e. df_data index values)\n",
        "    df['original_index'] = index_vals_list\n",
        "\n",
        "    # Now, score all retrieved passages using the cross_encoder\n",
        "    cross_scores = cross_encoder.predict(cross_input_list)\n",
        "\n",
        "    # Add the scores to the dataframe\n",
        "    df['cross_scores'] = cross_scores\n",
        "\n",
        "    # Sort the DataFrame in descending order based on the scores\n",
        "    df_sorted = df.sort_values(by='cross_scores', ascending=False)\n",
        "\n",
        "    # Reset the index (*This was missed previously*)\n",
        "    df_sorted = df_sorted.reset_index(drop=True)\n",
        "\n",
        "    pred_list = []\n",
        "\n",
        "    for i in range(0,len(df_sorted)):\n",
        "\n",
        "        text = df_sorted.loc[i, 'pred_text']\n",
        "\n",
        "        # Get the arxiv id\n",
        "        # original_index refers to the index values in df_filtered\n",
        "        original_index = df_sorted.loc[i, 'original_index']\n",
        "        arxiv_id = df_data.loc[original_index, 'id']\n",
        "        cat_text = df_data.loc[original_index, 'cat_text']\n",
        "        title = df_data.loc[original_index, 'title']\n",
        "\n",
        "        # Crete the link to the research paper pdf\n",
        "        link_to_pdf = f'https://arxiv.org/pdf/{arxiv_id}'\n",
        "\n",
        "        item = {\n",
        "            'arxiv_id': arxiv_id,\n",
        "            'link_to_pdf': link_to_pdf,\n",
        "            'cat_text': cat_text,\n",
        "            'title': title,\n",
        "            'abstract': text\n",
        "        }\n",
        "\n",
        "        pred_list.append(item)\n",
        "\n",
        "    return pred_list\n",
        "\n",
        "\n",
        "def print_search_results(pred_list, num_results_to_print):\n",
        "\n",
        "    for i in range(0,num_results_to_print):\n",
        "\n",
        "        pred_dict = pred_list[i]\n",
        "\n",
        "        link_to_pdf = pred_dict['link_to_pdf']\n",
        "        abstract = pred_dict['abstract']\n",
        "        cat_text = pred_dict['cat_text']\n",
        "        title = pred_dict['title']\n",
        "\n",
        "        print('Title:',title)\n",
        "        print('Categories:',cat_text)\n",
        "        print('Abstract:',abstract)\n",
        "        print('Link to pdf:',link_to_pdf)\n",
        "        print()\n",
        "\n",
        "\n",
        "def run_arxiv_search(query_text, num_results_to_print, top_k=300):\n",
        "\n",
        "    # Run a faiss greedy search\n",
        "    pred_index_list = run_faiss_search(query_text, top_k)\n",
        "\n",
        "    # This returns a list of dicts with length equal to top_k\n",
        "    pred_list = run_rerank(pred_index_list, query_text)\n",
        "\n",
        "    # Print the results\n",
        "    print_search_results(pred_list, num_results_to_print)\n",
        ""
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-02-29T12:34:19.334241Z",
          "iopub.execute_input": "2024-02-29T12:34:19.33453Z",
          "iopub.status.idle": "2024-02-29T12:34:19.349413Z",
          "shell.execute_reply.started": "2024-02-29T12:34:19.334505Z",
          "shell.execute_reply": "2024-02-29T12:34:19.348636Z"
        },
        "trusted": true,
        "id": "O-mhM4gLDdT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the embedding vectors and the dataframe\n",
        "\n",
        "We will load the embeddings and the dataframe from the ouput of the Part 1 notebook."
      ],
      "metadata": {
        "id": "I-G3O0zYDdT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the compressed array\n",
        "embeddings = np.load(PATH_TO_EMBEDS)\n",
        "\n",
        "# Access the array by the name you specified ('my_array' in this case)\n",
        "embeddings = embeddings['array_data']\n",
        "\n",
        "embeddings.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-29T12:34:19.350391Z",
          "iopub.execute_input": "2024-02-29T12:34:19.350941Z",
          "iopub.status.idle": "2024-02-29T12:35:06.925654Z",
          "shell.execute_reply.started": "2024-02-29T12:34:19.350917Z",
          "shell.execute_reply": "2024-02-29T12:35:06.924664Z"
        },
        "trusted": true,
        "id": "HhfK7FWHDdT2",
        "outputId": "a9b155ed-79a7-4db4-b3e8-d9f4e56f0314"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(2421966, 384)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the compressed DataFrame\n",
        "\n",
        "df_data = pd.read_csv(PATH_TO_DF, compression='gzip')\n",
        "\n",
        "print(df_data.shape)\n",
        "\n",
        "#df_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-29T12:37:36.734232Z",
          "iopub.execute_input": "2024-02-29T12:37:36.735047Z",
          "iopub.status.idle": "2024-02-29T12:38:52.102134Z",
          "shell.execute_reply.started": "2024-02-29T12:37:36.735016Z",
          "shell.execute_reply": "2024-02-29T12:38:52.10116Z"
        },
        "trusted": true,
        "id": "iRoc8e1cDdT2",
        "outputId": "fe5bd015-9519-44e1-c4f3-0c990d563115"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_35/3627369456.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n  df_data = pd.read_csv(PATH_TO_DF, compression='gzip')\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "(2421966, 6)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the packages"
      ],
      "metadata": {
        "id": "7LmoLpgMDdT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize FAISS\n",
        "\n",
        "import faiss\n",
        "\n",
        "embed_length = embeddings.shape[1]\n",
        "\n",
        "faiss_index = faiss.IndexFlatL2(embed_length)\n",
        "\n",
        "# Add the embeddings to the index\n",
        "faiss_index.add(embeddings)\n",
        "\n",
        "faiss_index.is_trained"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-29T13:03:07.007678Z",
          "iopub.execute_input": "2024-02-29T13:03:07.008509Z",
          "iopub.status.idle": "2024-02-29T13:03:10.195615Z",
          "shell.execute_reply.started": "2024-02-29T13:03:07.008479Z",
          "shell.execute_reply": "2024-02-29T13:03:10.194688Z"
        },
        "trusted": true,
        "id": "g_6jCTQqDdT2",
        "outputId": "2f681fb1-7c3b-48cb-d854-9131682ed1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize sentence_transformers\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-02-29T13:03:10.197894Z",
          "iopub.execute_input": "2024-02-29T13:03:10.198557Z",
          "iopub.status.idle": "2024-02-29T13:03:22.117806Z",
          "shell.execute_reply.started": "2024-02-29T13:03:10.198519Z",
          "shell.execute_reply": "2024-02-29T13:03:22.116988Z"
        },
        "trusted": true,
        "id": "0KeXLWnpDdT3",
        "outputId": "6af73df7-e1de-407d-ccc1-0c855e24cbdd",
        "colab": {
          "referenced_widgets": [
            "5c70d35f1d0940c2951ed2df7b5c4461",
            "dc54f77f624f42ba95a1fd835fd1f9f8",
            "dbade627e9154549bb14c574b43fa57d",
            "c6aa971cb1f040d1aec9c057576d3dd2",
            "cfdea042b3f9456ea4703c79691e8db5",
            "feb2224a5245484f8055f4b016dca34c",
            "1be7e96691dc4fc8b6d9dfa98ad813ff",
            "d112a9d2c4b24157b6409e8294dda243",
            "8e0f006067654f9caefd099592860a97",
            "343d65eb1a8d496198da60ca9573246d",
            "0df7f833a49d40d0b8c18444d33cc321"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c70d35f1d0940c2951ed2df7b5c4461"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc54f77f624f42ba95a1fd835fd1f9f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbade627e9154549bb14c574b43fa57d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6aa971cb1f040d1aec9c057576d3dd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfdea042b3f9456ea4703c79691e8db5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "feb2224a5245484f8055f4b016dca34c"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1be7e96691dc4fc8b6d9dfa98ad813ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d112a9d2c4b24157b6409e8294dda243"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e0f006067654f9caefd099592860a97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "343d65eb1a8d496198da60ca9573246d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0df7f833a49d40d0b8c18444d33cc321"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the cross_encoder for reranking\n",
        "\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "# We use a cross-encoder, to re-rank the results list to improve the quality\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-29T13:03:22.118833Z",
          "iopub.execute_input": "2024-02-29T13:03:22.119271Z",
          "iopub.status.idle": "2024-02-29T13:03:24.056947Z",
          "shell.execute_reply.started": "2024-02-29T13:03:22.119245Z",
          "shell.execute_reply": "2024-02-29T13:03:24.056261Z"
        },
        "trusted": true,
        "id": "QvedPfdhDdT3",
        "outputId": "44064cd7-c21f-45fd-9b0c-ec1b7c8087aa",
        "colab": {
          "referenced_widgets": [
            "088b415e4a12447aa73ef42cb12adecf",
            "7ee4986786da41fc83528da65846330e",
            "8eaf76eac5b0465ca379b3909fefb4a5",
            "6449444376bf4d7f867dd309b3d64d24",
            "d5f511d591124de088fa9ad54c1b1024"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "088b415e4a12447aa73ef42cb12adecf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ee4986786da41fc83528da65846330e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8eaf76eac5b0465ca379b3909fefb4a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6449444376bf4d7f867dd309b3d64d24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5f511d591124de088fa9ad54c1b1024"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------- #\n",
        "# RUN A SEARCH"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-29T13:03:24.058105Z",
          "iopub.execute_input": "2024-02-29T13:03:24.058483Z",
          "iopub.status.idle": "2024-02-29T13:03:24.062409Z",
          "shell.execute_reply.started": "2024-02-29T13:03:24.058447Z",
          "shell.execute_reply": "2024-02-29T13:03:24.061518Z"
        },
        "trusted": true,
        "id": "wxrvnlJzDdT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run a search\n",
        "\n",
        "You'll notice that the title is still appended to the abstract. I left it in as a visual check to ensure that I haven't made any errors when displaying the results.\n",
        "\n",
        "1- You might improve the search results by\n",
        "providing more details in your search query.<br>\n",
        "2- I suggest that you enter a similar search query on the ArXiv website to compare the search results and the user experience.<br>\n",
        "https://arxiv.org/search/advanced"
      ],
      "metadata": {
        "id": "42BICocoDdT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# *** PLEASE ENTER YOUR SEARCH QUERY HERE ***\n",
        "\n",
        "query_text = \"\"\"\n",
        "\n",
        "privacy exploit on synthetic data\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# RUN THE SEARCH\n",
        "num_results_to_print = 20 # top_k = 300\n",
        "run_arxiv_search(query_text, num_results_to_print)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-29T13:13:52.022576Z",
          "iopub.execute_input": "2024-02-29T13:13:52.022971Z",
          "iopub.status.idle": "2024-02-29T13:13:54.768898Z",
          "shell.execute_reply.started": "2024-02-29T13:13:52.022941Z",
          "shell.execute_reply": "2024-02-29T13:13:54.767873Z"
        },
        "trusted": true,
        "id": "Ctbn2hDSDdT3",
        "outputId": "e10c4333-7b65-4324-dadc-289cc28025e4",
        "colab": {
          "referenced_widgets": [
            "8adb5d5340be4c8cb91bacae3003cddb",
            "8849caef846a46248e4af2391a520b44"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8adb5d5340be4c8cb91bacae3003cddb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/10 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8849caef846a46248e4af2391a520b44"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Title: TAPAS: a Toolbox for Adversarial Privacy Auditing of Synthetic Data\nCategories: Cryptography and Security, Artificial Intelligence, Machine Learning\nAbstract: TAPAS: a Toolbox for Adversarial Privacy Auditing of Synthetic Data {title} Personal data collected at scale promises to improve decision-making and accelerate innovation. However, sharing and using such data raises serious privacy concerns. A promising solution is to produce synthetic data, artificial records to share instead of real data. Since synthetic records are not linked to real persons, this intuitively prevents classical re-identification attacks. However, this is insufficient to protect privacy. We here present TAPAS, a toolbox of attacks to evaluate synthetic data privacy under a wide range of scenarios. These attacks include generalizations of prior works and novel attacks. We also introduce a general framework for reasoning about privacy threats to synthetic data and showcase TAPAS on several examples.\nLink to pdf: https://arxiv.org/pdf/2211.0655\n\nTitle: Differentially Private Synthetic Data Using KD-Trees\nCategories: Cryptography and Security, Machine Learning, Machine Learning\nAbstract: Differentially Private Synthetic Data Using KD-Trees {title} Creation of a synthetic dataset that faithfully represents the data distribution and simultaneously preserves privacy is a major research challenge. Many space partitioning based approaches have emerged in recent years for answering statistical queries in a differentially private manner. However, for synthetic data generation problem, recent research has been mainly focused on deep generative models. In contrast, we exploit space partitioning techniques together with noise perturbation and thus achieve intuitive and transparent algorithms. We propose both data independent and data dependent algorithms for $\\epsilon$-differentially private synthetic data generation whose kernel density resembles that of the real dataset. Additionally, we provide theoretical results on the utility-privacy trade-offs and show how our data dependent approach overcomes the curse of dimensionality and leads to a scalable algorithm. We show empirical utility improvements over the prior work, and discuss performance of our algorithm on a downstream classification task on a real dataset.\nLink to pdf: https://arxiv.org/pdf/2306.13211\n\nTitle: Privacy of synthetic data: a statistical framework\nCategories: Cryptography and Security, Statistics Theory, Statistics Theory\nAbstract: Privacy of synthetic data: a statistical framework {title} Privacy-preserving data analysis is emerging as a challenging problem with far-reaching impact. In particular, synthetic data are a promising concept toward solving the aporetic conflict between data privacy and data sharing. Yet, it is known that accurately generating private, synthetic data of certain kinds is NP-hard. We develop a statistical framework for differentially private synthetic data, which enables us to circumvent the computational hardness of the problem. We consider the true data as a random sample drawn from a population Omega according to some unknown density. We then replace Omega by a much smaller random subset Omega^*, which we sample according to some known density. We generate synthetic data on the reduced space Omega^* by fitting the specified linear statistics obtained from the true data. To ensure privacy we use the common Laplacian mechanism. Employing the concept of Renyi condition number, which measures how well the sampling distribution is correlated with the population distribution, we derive explicit bounds on the privacy and accuracy provided by the proposed method.\nLink to pdf: https://arxiv.org/pdf/2109.01748\n\nTitle: A Unified Framework for Quantifying Privacy Risk in Synthetic Data\nCategories: Cryptography and Security\nAbstract: A Unified Framework for Quantifying Privacy Risk in Synthetic Data {title} Synthetic data is often presented as a method for sharing sensitive information in a privacy-preserving manner by reproducing the global statistical properties of the original data without disclosing sensitive information about any individual. In practice, as with other anonymization methods, privacy risks cannot be entirely eliminated. The residual privacy risks need instead to be ex-post assessed. We present Anonymeter, a statistical framework to jointly quantify different types of privacy risks in synthetic tabular datasets. We equip this framework with attack-based evaluations for the singling out, linkability, and inference risks, the three key indicators of factual anonymization according to the European General Data Protection Regulation (GDPR). To the best of our knowledge, we are the first to introduce a coherent and legally aligned evaluation of these three privacy risks for synthetic data, and to design privacy attacks which model directly the singling out and linkability risks. We demonstrate the effectiveness of our methods by conducting an extensive set of experiments that measure the privacy risks of data with deliberately inserted privacy leakages, and of synthetic data generated with and without differential privacy. Our results highlight that the three privacy risks reported by our framework scale linearly with the amount of privacy leakage in the data. Furthermore, we observe that synthetic data exhibits the lowest vulnerability against linkability, indicating one-to-one relationships between real and synthetic data records are not preserved. Finally, we demonstrate quantitatively that Anonymeter outperforms existing synthetic data privacy evaluation frameworks both in terms of detecting privacy leaks, as well as computation speed. To contribute to a privacy-conscious usage of synthetic data, we open source Anonymeter at https://github.com/statice/anonymeter.\nLink to pdf: https://arxiv.org/pdf/2211.10459\n\nTitle: Privacy-preserving data sharing via probabilistic modelling\nCategories: Machine Learning, Cryptography and Security, Machine Learning\nAbstract: Privacy-preserving data sharing via probabilistic modelling {title} Differential privacy allows quantifying privacy loss resulting from accessing sensitive personal data. Repeated accesses to underlying data incur increasing loss. Releasing data as privacy-preserving synthetic data would avoid this limitation, but would leave open the problem of designing what kind of synthetic data. We propose formulating the problem of private data release through probabilistic modelling. This approach transforms the problem of designing the synthetic data into choosing a model for the data, allowing also including prior knowledge, which improves the quality of the synthetic data. We demonstrate empirically, in an epidemiological study, that statistical discoveries can be reliably reproduced from the synthetic data. We expect the method to have broad use in creating high-quality anonymized data twins of key data sets for research.\nLink to pdf: https://arxiv.org/pdf/1912.04439\n\nTitle: Synthetic Data -- Anonymisation Groundhog Day\nCategories: Machine Learning, Cryptography and Security\nAbstract: Synthetic Data -- Anonymisation Groundhog Day {title} Synthetic data has been advertised as a silver-bullet solution to privacy-preserving data publishing that addresses the shortcomings of traditional anonymisation techniques. The promise is that synthetic data drawn from generative models preserves the statistical properties of the original dataset but, at the same time, provides perfect protection against privacy attacks. In this work, we present the first quantitative evaluation of the privacy gain of synthetic data publishing and compare it to that of previous anonymisation techniques.   Our evaluation of a wide range of state-of-the-art generative models demonstrates that synthetic data either does not prevent inference attacks or does not retain data utility. In other words, we empirically show that synthetic data does not provide a better tradeoff between privacy and utility than traditional anonymisation techniques.   Furthermore, in contrast to traditional anonymisation, the privacy-utility tradeoff of synthetic data publishing is hard to predict. Because it is impossible to predict what signals a synthetic dataset will preserve and what information will be lost, synthetic data leads to a highly variable privacy gain and unpredictable utility loss. In summary, we find that synthetic data is far from the holy grail of privacy-preserving data publishing.\nLink to pdf: https://arxiv.org/pdf/2011.07018\n\nTitle: PreFair: Privately Generating Justifiably Fair Synthetic Data\nCategories: Cryptography and Security, Computers and Society, Databases\nAbstract: PreFair: Privately Generating Justifiably Fair Synthetic Data {title} When a database is protected by Differential Privacy (DP), its usability is limited in scope. In this scenario, generating a synthetic version of the data that mimics the properties of the private data allows users to perform any operation on the synthetic data, while maintaining the privacy of the original data. Therefore, multiple works have been devoted to devising systems for DP synthetic data generation. However, such systems may preserve or even magnify properties of the data that make it unfair, endering the synthetic data unfit for use. In this work, we present PreFair, a system that allows for DP fair synthetic data generation. PreFair extends the state-of-the-art DP data generation mechanisms by incorporating a causal fairness criterion that ensures fair synthetic data. We adapt the notion of justifiable fairness to fit the synthetic data generation scenario. We further study the problem of generating DP fair synthetic data, showing its intractability and designing algorithms that are optimal under certain assumptions. We also provide an extensive experimental evaluation, showing that PreFair generates synthetic data that is significantly fairer than the data generated by leading DP data generation mechanisms, while remaining faithful to the private data.\nLink to pdf: https://arxiv.org/pdf/2212.1031\n\nTitle: Advancing Microdata Privacy Protection: A Review of Synthetic Data\nCategories: Methodology\nAbstract: Advancing Microdata Privacy Protection: A Review of Synthetic Data {title} Synthetic data generation is a powerful tool for privacy protection when considering public release of record-level data files. Initially proposed about three decades ago, it has generated significant research and application interest. To meet the pressing demand of data privacy protection in a variety of contexts, the field needs more researchers and practitioners. This review provides a comprehensive introduction to synthetic data, including technical details of their generation and evaluation. Our review also addresses the challenges and limitations of synthetic data, discusses practical applications, and provides thoughts for future work.\nLink to pdf: https://arxiv.org/pdf/2308.00872\n\nTitle: Privacy-Preserving Synthetic Datasets Over Weakly Constrained Domains\nCategories: Databases\nAbstract: Privacy-Preserving Synthetic Datasets Over Weakly Constrained Domains {title} Techniques to deliver privacy-preserving synthetic datasets take a sensitive dataset as input and produce a similar dataset as output while maintaining differential privacy. These approaches have the potential to improve data sharing and reuse, but they must be accessible to non-experts and tolerant of realistic data. Existing approaches make an implicit assumption that the active domain of the dataset is similar to the global domain, potentially violating differential privacy.   In this paper, we present an algorithm for generating differentially private synthetic data over the large, weakly constrained domains we find in realistic open data situations. Our algorithm models the unrepresented domain analytically as a probability distribution to adjust the output and compute noise, avoiding the need to compute the full domain explicitly. We formulate the tradeoff between privacy and utility in terms of a \"tolerance for randomness\" parameter that does not require users to inspect the data to set. Finally, we show that the algorithm produces sensible results on real datasets.\nLink to pdf: https://arxiv.org/pdf/1808.07603\n\nTitle: In Defense of Synthetic Data\nCategories: Databases\nAbstract: In Defense of Synthetic Data {title} Synthetic datasets have long been thought of as second-rate, to be used only when \"real\" data collected directly from the real world is unavailable. But this perspective assumes that raw data is clean, unbiased, and trustworthy, which it rarely is. Moreover, the benefits of synthetic data for privacy and for bias correction are becoming increasingly important in any domain that works with people. Curated synthetic datasets - synthetic data derived from minimal perturbations of real data - enable early stage product development and collaboration, protect privacy, afford reproducibility, increase dataset diversity in research, and protect disadvantaged groups from problematic inferences on the original data that reflects systematic discrimination. Rather than representing a departure from the true state of the world, in this paper we argue that properly generated synthetic data is a step towards responsible and equitable research and development of machine learning systems.\nLink to pdf: https://arxiv.org/pdf/1905.01351\n\nTitle: Mitigating Statistical Bias within Differentially Private Synthetic Data\nCategories: Machine Learning, Cryptography and Security, Machine Learning\nAbstract: Mitigating Statistical Bias within Differentially Private Synthetic Data {title} Increasing interest in privacy-preserving machine learning has led to new and evolved approaches for generating private synthetic data from undisclosed real data. However, mechanisms of privacy preservation can significantly reduce the utility of synthetic data, which in turn impacts downstream tasks such as learning predictive models or inference. We propose several re-weighting strategies using privatised likelihood ratios that not only mitigate statistical bias of downstream estimators but also have general applicability to differentially private generative models. Through large-scale empirical evaluation, we show that private importance weighting provides simple and effective privacy-compliant augmentation for general applications of synthetic data.\nLink to pdf: https://arxiv.org/pdf/2108.10934\n\nTitle: Decentralised, Scalable and Privacy-Preserving Synthetic Data Generation\nCategories: Cryptography and Security, Machine Learning\nAbstract: Decentralised, Scalable and Privacy-Preserving Synthetic Data Generation {title} Synthetic data is emerging as a promising way to harness the value of data, while reducing privacy risks. The potential of synthetic data is not limited to privacy-friendly data release, but also includes complementing real data in use-cases such as training machine learning algorithms that are more fair and robust to distribution shifts etc. There is a lot of interest in algorithmic advances in synthetic data generation for providing better privacy and statistical guarantees and for its better utilisation in machine learning pipelines. However, for responsible and trustworthy synthetic data generation, it is not sufficient to focus only on these algorithmic aspects and instead, a holistic view of the synthetic data generation pipeline must be considered. We build a novel system that allows the contributors of real data to autonomously participate in differentially private synthetic data generation without relying on a trusted centre. Our modular, general and scalable solution is based on three building blocks namely: Solid (Social Linked Data), MPC (Secure Multi-Party Computation) and Trusted Execution Environments (TEEs). Solid is a specification that lets people store their data securely in decentralised data stores called Pods and control access to their data. MPC refers to the set of cryptographic methods for different parties to jointly compute a function over their inputs while keeping those inputs private. TEEs such as Intel SGX rely on hardware based features for confidentiality and integrity of code and data. We show how these three technologies can be effectively used to address various challenges in responsible and trustworthy synthetic data generation by ensuring: 1) contributor autonomy, 2) decentralisation, 3) privacy and 4) scalability. We support our claims with rigorous empirical results on simulated and real datasets and different synthetic data generation algorithms.\nLink to pdf: https://arxiv.org/pdf/2310.20062\n\nTitle: Synthetic is all you need: removing the auxiliary data assumption for   membership inference attacks against synthetic data\nCategories: Cryptography and Security, Artificial Intelligence\nAbstract: Synthetic is all you need: removing the auxiliary data assumption for   membership inference attacks against synthetic data {title} Synthetic data is emerging as one of the most promising solutions to share individual-level data while safeguarding privacy. While membership inference attacks (MIAs), based on shadow modeling, have become the standard to evaluate the privacy of synthetic data, they currently assume the attacker to have access to an auxiliary dataset sampled from a similar distribution as the training dataset. This is often seen as a very strong assumption in practice, especially as the proposed main use cases for synthetic tabular data (e.g. medical data, financial transactions) are very specific and don't have any reference datasets directly available. We here show how this assumption can be removed, allowing for MIAs to be performed using only the synthetic data. Specifically, we developed three different scenarios: (S1) Black-box access to the generator, (S2) only access to the released synthetic dataset and (S3) a theoretical setup as upper bound for the attack performance using only synthetic data. Our results show that MIAs are still successful, across two real-world datasets and two synthetic data generators. These results show how the strong hypothesis made when auditing synthetic data releases - access to an auxiliary dataset - can be relaxed, making the attacks more realistic in practice.\nLink to pdf: https://arxiv.org/pdf/2307.01701\n\nTitle: Privacy-Preserving Synthetic Data Generation for Recommendation Systems\nCategories: Information Retrieval\nAbstract: Privacy-Preserving Synthetic Data Generation for Recommendation Systems {title} Recommendation systems make predictions chiefly based on users' historical interaction data (e.g., items previously clicked or purchased). There is a risk of privacy leakage when collecting the users' behavior data for building the recommendation model. However, existing privacy-preserving solutions are designed for tackling the privacy issue only during the model training and results collection phases. The problem of privacy leakage still exists when directly sharing the private user interaction data with organizations or releasing them to the public. To address this problem, in this paper, we present a User Privacy Controllable Synthetic Data Generation model (short for UPC-SDG), which generates synthetic interaction data for users based on their privacy preferences. The generation model aims to provide certain privacy guarantees while maximizing the utility of the generated synthetic data at both data level and item level. Specifically, at the data level, we design a selection module that selects those items that contribute less to a user's preferences from the user's interaction data. At the item level, a synthetic data generation module is proposed to generate a synthetic item corresponding to the selected item based on the user's preferences. Furthermore, we also present a privacy-utility trade-off strategy to balance the privacy and utility of the synthetic data. Extensive experiments and ablation studies have been conducted on three publicly accessible datasets to justify our method, demonstrating its effectiveness in generating synthetic data under users' privacy preferences.\nLink to pdf: https://arxiv.org/pdf/2209.13133\n\nTitle: Membership Inference Attacks against Synthetic Data through Overfitting   Detection\nCategories: Machine Learning, Cryptography and Security\nAbstract: Membership Inference Attacks against Synthetic Data through Overfitting   Detection {title} Data is the foundation of most science. Unfortunately, sharing data can be obstructed by the risk of violating data privacy, impeding research in fields like healthcare. Synthetic data is a potential solution. It aims to generate data that has the same distribution as the original data, but that does not disclose information about individuals. Membership Inference Attacks (MIAs) are a common privacy attack, in which the attacker attempts to determine whether a particular real sample was used for training of the model. Previous works that propose MIAs against generative models either display low performance -- giving the false impression that data is highly private -- or need to assume access to internal generative model parameters -- a relatively low-risk scenario, as the data publisher often only releases synthetic data, not the model. In this work we argue for a realistic MIA setting that assumes the attacker has some knowledge of the underlying data distribution. We propose DOMIAS, a density-based MIA model that aims to infer membership by targeting local overfitting of the generative model. Experimentally we show that DOMIAS is significantly more successful at MIA than previous work, especially at attacking uncommon samples. The latter is disconcerting since these samples may correspond to underrepresented groups. We also demonstrate how DOMIAS' MIA performance score provides an interpretable metric for privacy, giving data publishers a new tool for achieving the desired privacy-utility trade-off in their synthetic data.\nLink to pdf: https://arxiv.org/pdf/2302.1258\n\nTitle: High Epsilon Synthetic Data Vulnerabilities in MST and PrivBayes\nCategories: Cryptography and Security\nAbstract: High Epsilon Synthetic Data Vulnerabilities in MST and PrivBayes {title} Synthetic data generation (SDG) has become increasingly popular as a privacy-enhancing technology. It aims to maintain important statistical properties of its underlying training data, while excluding any personally identifiable information. There have been a whole host of SDG algorithms developed in recent years to improve and balance both of these aims. Many of these algorithms provide robust differential privacy guarantees.   However, we show here that if the differential privacy parameter $\\varepsilon$ is set too high, then unambiguous privacy leakage can result. We show this by conducting a novel membership inference attack (MIA) on two state-of-the-art differentially private SDG algorithms: MST and PrivBayes. Our work suggests that there are vulnerabilities in these generators not previously seen, and that future work to strengthen their privacy is advisable.   We present the heuristic for our MIA here. It assumes knowledge of auxiliary \"population\" data, and also assumes knowledge of which SDG algorithm was used. We use this information to adapt the recent DOMIAS MIA uniquely to MST and PrivBayes. Our approach went on to win the SNAKE challenge in November 2023.\nLink to pdf: https://arxiv.org/pdf/2402.06699\n\nTitle: Scaling While Privacy Preserving: A Comprehensive Synthetic Tabular Data   Generation and Evaluation in Learning Analytics\nCategories: Cryptography and Security, Artificial Intelligence\nAbstract: Scaling While Privacy Preserving: A Comprehensive Synthetic Tabular Data   Generation and Evaluation in Learning Analytics {title} Privacy poses a significant obstacle to the progress of learning analytics (LA), presenting challenges like inadequate anonymization and data misuse that current solutions struggle to address. Synthetic data emerges as a potential remedy, offering robust privacy protection. However, prior LA research on synthetic data lacks thorough evaluation, essential for assessing the delicate balance between privacy and data utility. Synthetic data must not only enhance privacy but also remain practical for data analytics. Moreover, diverse LA scenarios come with varying privacy and utility needs, making the selection of an appropriate synthetic data approach a pressing challenge. To address these gaps, we propose a comprehensive evaluation of synthetic data, which encompasses three dimensions of synthetic data quality, namely resemblance, utility, and privacy. We apply this evaluation to three distinct LA datasets, using three different synthetic data generation methods. Our results show that synthetic data can maintain similar utility (i.e., predictive performance) as real data, while preserving privacy. Furthermore, considering different privacy and data utility requirements in different LA scenarios, we make customized recommendations for synthetic data generation. This paper not only presents a comprehensive evaluation of synthetic data but also illustrates its potential in mitigating privacy concerns within the field of LA, thus contributing to a wider application of synthetic data in LA and promoting a better practice for open science.\nLink to pdf: https://arxiv.org/pdf/2401.06883\n\nTitle: Generating Poisson-Distributed Differentially Private Synthetic Data\nCategories: Methodology, Statistics Theory, Statistics Theory\nAbstract: Generating Poisson-Distributed Differentially Private Synthetic Data {title} The dissemination of synthetic data can be an effective means of making information from sensitive data publicly available while reducing the risk of disclosure associated with releasing the sensitive data directly. While mechanisms exist for synthesizing data that satisfy formal privacy guarantees, the utility of the synthetic data is often an afterthought. More recently, the use of methods from the disease mapping literature has been proposed to generate spatially-referenced synthetic data with high utility, albeit without formal privacy guarantees. The objective for this paper is to help bridge the gap between the disease mapping and the formal privacy literatures. In particular, we extend an existing approach for generating formally private synthetic data to the case of Poisson-distributed count data in a way that allows for the infusion of prior information. To evaluate the utility of the synthetic data, we conducted a simulation study inspired by publicly available, county-level heart disease-related death counts. The results of this study demonstrate that the proposed approach for generating differentially private synthetic data outperforms a popular technique when the counts correspond to events arising from subgroups with unequal population sizes or unequal event rates.\nLink to pdf: https://arxiv.org/pdf/1906.00455\n\nTitle: On R\\'{e}nyi Differential Privacy in Statistics-Based Synthetic Data   Generation\nCategories: Cryptography and Security, Information Theory, Information Theory\nAbstract: On R\\'{e}nyi Differential Privacy in Statistics-Based Synthetic Data   Generation {title} Privacy protection with synthetic data generation often uses differentially private statistics and model parameters to quantitatively express theoretical security. However, these methods do not take into account privacy protection due to the randomness of data generation. In this paper, we theoretically evaluate R\\'{e}nyi differential privacy of the randomness in data generation of a synthetic data generation method that uses the mean vector and the covariance matrix of an original dataset. Specifically, for a fixed $\\alpha > 1$, we show the condition of $\\varepsilon$ such that the synthetic data generation satisfies $(\\alpha, \\varepsilon)$-R\\'{e}nyi differential privacy under a bounded neighboring condition and an unbounded neighboring condition, respectively. In particular, under the unbounded condition, when the size of the original dataset and synthetic datase is 10 million, the mechanism satisfies $(4, 0.576)$-R\\'{e}nyi differential privacy. We also show that when we translate it into the traditional $(\\varepsilon, \\delta)$-differential privacy, the mechanism satisfies $(4.00, 10^{-10})$-differential privacy.\nLink to pdf: https://arxiv.org/pdf/2303.17849\n\nTitle: Achilles' Heels: Vulnerable Record Identification in Synthetic Data   Publishing\nCategories: Cryptography and Security, Artificial Intelligence\nAbstract: Achilles' Heels: Vulnerable Record Identification in Synthetic Data   Publishing {title} Synthetic data is seen as the most promising solution to share individual-level data while preserving privacy. Shadow modeling-based Membership Inference Attacks (MIAs) have become the standard approach to evaluate the privacy risk of synthetic data. While very effective, they require a large number of datasets to be created and models trained to evaluate the risk posed by a single record. The privacy risk of a dataset is thus currently evaluated by running MIAs on a handful of records selected using ad-hoc methods. We here propose what is, to the best of our knowledge, the first principled vulnerable record identification technique for synthetic data publishing, leveraging the distance to a record's closest neighbors. We show our method to strongly outperform previous ad-hoc methods across datasets and generators. We also show evidence of our method to be robust to the choice of MIA and to specific choice of parameters. Finally, we show it to accurately identify vulnerable records when synthetic data generators are made differentially private. The choice of vulnerable records is as important as more accurate MIAs when evaluating the privacy of synthetic data releases, including from a legal perspective. We here propose a simple yet highly effective method to do so. We hope our method will enable practitioners to better estimate the risk posed by synthetic data publishing and researchers to fairly compare ever improving MIAs on synthetic data.\nLink to pdf: https://arxiv.org/pdf/2306.10308\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3yoxUQKHDdT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QPmJtNUYDdT3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}